{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Это старая предобработка фич\n",
    "\n",
    "Она во многом похожа на новую, но немного хуже.\n",
    "\n",
    "Участвует при обучении модели, дающей итоговой сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import re, pickle, logging, json, gc, utils\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "R = 6373.0 # радиус земли в километрах\n",
    "\n",
    "def distance(x, y):\n",
    "    lat_a, long_a, lat_b, long_b = map(radians, [*x,*y])  \n",
    "    dlon = long_b - long_a\n",
    "    dlat = lat_b - lat_a\n",
    "    a = sin(0.5 * dlat)**2 + cos(lat_a) * cos(lat_b) * sin(0.5 * dlon)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "HOLDOUT_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/configs/config.json') as f:\n",
    "    cfg = json.load(f)\n",
    "    \n",
    "metro_rad_values = cfg['metro']['radius_values']\n",
    "\n",
    "atm_rad_values = cfg['atm']['radius_values']\n",
    "atm_k_values = cfg['atm']['k_values']\n",
    "atm_group_rad_values = cfg['atm']['group_radius_values']\n",
    "\n",
    "osm = cfg['osm']\n",
    "\n",
    "rosbank_rad_values = cfg['rosbank']['radius_values']\n",
    "\n",
    "metro_diff_k_values = [10, 50]\n",
    "sber_diff_k_values = [10, 100]\n",
    "atm_diff_k_values = [15, 100]\n",
    "city_diff_k_values = [10, 100]\n",
    "rosbank_diff_k_values = [10, 100]\n",
    "sravni_diff_k_values = [10, 100]\n",
    "rshb_diff_k_values = [10, 50]\n",
    "raif_diff_k_values = [10, 50]\n",
    "gazprom_diff_k_values = [10, 50]\n",
    "partners_diff_k_values = [10, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='./data/logs/logfile.log', level=logging.INFO, \n",
    "                    format='%(asctime)s %(message)s', datefmt='%I:%M:%S. ')\n",
    "logging.info('Reading data.csv')\n",
    "\n",
    "data = pd.read_csv(\"./data/prep/data.csv\")\n",
    "groups = data['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# holdout mode\n",
    "if HOLDOUT_MODE:\n",
    "    holdout = range(5009, 6261)\n",
    "\n",
    "    data['isHoldout'] = [el in holdout for el in range(data.shape[0])]\n",
    "    data.loc[holdout, 'isTrain'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, связанные с метро\n",
    "\n",
    "+ Расстояние до ближайшей станции метро\n",
    "+ Количество станций в радиусе одного км"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99ef35c4fe74055b2f3616fee5db5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7016b34b20424ad9a7263e042ce68560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6f359a45844b408d423e7c05d5b3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "metro_fields = {\n",
    "    'metro': ['town', 'line', 'station'],\n",
    "    'metro_moscow': ['station'],\n",
    "    'metro_peter': ['station']\n",
    "}\n",
    "\n",
    "metro_new_features = []\n",
    "metro_new_features += ['min_diff']\n",
    "for k in metro_diff_k_values:\n",
    "    metro_new_features += ['diff_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "\n",
    "for filename in metro_fields:\n",
    "    df = pd.read_csv(\"./data/prep/\" + filename + \".csv\")\n",
    "    coords = df[['lat', 'lon']].values\n",
    "    neigh = NearestNeighbors(metric=distance)\n",
    "    neigh.fit(coords)\n",
    "    \n",
    "    distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 50, return_distance=True)\n",
    "    \n",
    "    data[filename + '_dist'] = distances[:, 0]\n",
    "    data[filename + '_lat'] = df.loc[indexes[:, 0], 'lat'].values\n",
    "    data[filename + '_lon'] = df.loc[indexes[:, 0], 'lon'].values\n",
    "\n",
    "    for name in metro_fields[filename]:\n",
    "        data[filename + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "        tmp = data.groupby([filename + '_' + name, 'group']).size()\n",
    "        data[filename + '_' + name + '_group_amount'] = data[[filename + '_' + name, 'group']]\\\n",
    "                                    .apply(lambda x: tmp.get((x[filename + '_' + name], x['group']), 0.), axis=1)\n",
    "            \n",
    "            \n",
    "    stats = []\n",
    "    for idx, (dists, ids) in tqdm_notebook(enumerate(zip(distances, indexes)), leave=False):\n",
    "        info = []\n",
    "        diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "        info.append(diffs[0])\n",
    "        for k in [15, 50]:\n",
    "            info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "        stats.append(info)\n",
    "    data[[filename + '_' + word for word in metro_new_features]] = pd.DataFrame(stats)\n",
    "    \n",
    "    for rad in metro_rad_values:\n",
    "        data[filename + '_dist_count_' + str(rad)] = (distances < rad).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Избирательные участки\n",
    "\n",
    "+ Расстояние до ближайшего участка\n",
    "+ Широта и долгота ближайшего участка\n",
    "+ Для типа, региона, города, типа объекта, и адреса ближайшего участка считаются признаки:\n",
    "  + Количество объектов в выборке с такой же категорией (с таким же городом, регионом и т.п.)\n",
    "  + Количество объектов с такой же категорией и такой же группой, как и у объекта, для которого считается признак\n",
    "  + отношение второй величины к первой, то есть доля объектов с такой же группой среди всех объектов данной категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.5 s, sys: 163 ms, total: 49.7 s\n",
      "Wall time: 49.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "votes = pd.read_csv(\"./data/prep/votes.csv\")\n",
    "coords = votes[['lat', 'lon']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "    \n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 2, return_distance=True)\n",
    "\n",
    "PREFIX = 'izbir'\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['lat', 'lon', 'type', 'region', 'location_type', 'town', 'voters_in', 'voters_out', 'idx', 'address']:\n",
    "    data[PREFIX + '_' + name] = votes.loc[indexes[:, 0], name].values\n",
    "    \n",
    "for name in ['type', 'region', 'location_type', 'town', 'address']:\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        data[PREFIX + '_' + name + '_group_' + str(group) + '_amount'] = data[PREFIX + '_' + name] \\\n",
    "                            .map(data.groupby(PREFIX + '_' + name)['group'] \\\n",
    "                            .apply(lambda x: (x == group).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, связанные с банкоматами из выборки\n",
    "\n",
    "+ Расстояние до ближайшего другого банкомата\n",
    "+ Количество банкоматов в радиусах 0.05, 0.1, 0.3, 0.5, 1\n",
    "+ Стандартное отклонение расстояний до самых близких 40 банкоматов\n",
    "+ Доля банкоматов из той или иной группы в радиусах 0.1, 0.5, 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9600c4490394f53b3ae77ef8c29ea58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0734b4c5c0c04b52b41dafe807b612c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info('creating atm related features')\n",
    "\n",
    "data_coords = data[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(data_coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "\n",
    "import scipy.stats as sts\n",
    "\n",
    "groups = data['group'].unique()\n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in tqdm_notebook(enumerate(zip(distances, indexes))):\n",
    "    \n",
    "    info = []\n",
    "    \n",
    "    curr_group = data.loc[idx, 'group']\n",
    "    curr_dists = dists[ids != idx]\n",
    "    min_dist = curr_dists[0]\n",
    "    curr_ids = ids[ids != idx]\n",
    "    \n",
    "    min_ids = curr_ids[curr_dists == min_dist]\n",
    "    n = len(min_ids)\n",
    "    info.append(n)\n",
    "    cnt = data.loc[min_ids, 'group'].value_counts()\n",
    "    group_counts = [cnt.get(group, 0) / n for group in groups]\n",
    "    info += group_counts\n",
    "    tmp = np.array(group_counts)\n",
    "    info += [(tmp[tmp != 0] * np.log(tmp[tmp != 0])).sum()]\n",
    "    info.append(min_dist)\n",
    "    \n",
    "    if min_dist == 0:\n",
    "        info.append(1)\n",
    "    else:\n",
    "        info.append(0)\n",
    "\n",
    "    for k in atm_diff_k_values:\n",
    "        curr_k_dists = curr_dists[:k]\n",
    "        diffs = [curr_k_dists[i + 1] - curr_k_dists[i] for i in range(len(curr_k_dists) - 1)]\n",
    "        if len(diffs) > 0:\n",
    "            info += [np.mean(diffs), np.max(diffs), np.std(diffs)]\n",
    "        else:\n",
    "            info += [0] * 3\n",
    "        \n",
    "    for group in groups:\n",
    "        mask = data.loc[curr_ids, 'group'] == group\n",
    "        \n",
    "        if mask.sum() == 0:\n",
    "            info += [0] * 2\n",
    "        else:\n",
    "            curr_group_ids = curr_ids[mask]\n",
    "            curr_group_dists = curr_dists[mask]\n",
    "\n",
    "            min_group_dist = curr_group_dists[0]\n",
    "            min_group_ids = curr_group_ids[curr_group_dists == min_group_dist]\n",
    "            group_n = len(min_group_ids)\n",
    "            info.append(group_n)\n",
    "            info.append(min_group_dist)\n",
    "    \n",
    "    res.append(info)\n",
    "    \n",
    "new_atm_features = ['atm_min_len'] + ['atm_min_freq_' + str(group) for group in groups] + ['group_entropy']\n",
    "new_atm_features += ['atm_min_dist', 'atm_min_is_0']\n",
    "for k in atm_diff_k_values:\n",
    "    new_atm_features += ['atm_diff_' + str(k) + '_' + word for word in ['mean' ,'max', 'std']]\n",
    "for group in groups:\n",
    "    new_atm_features += ['atm_min_group_len_' + str(group), 'atm_min_group_dist_' + str(group)]\n",
    "#new_atm_features += ['atm_target_mean', 'atm_target_std', 'atm_target_dist']\n",
    "#new_atm_features += ['atm_group_target_mean', 'atm_group_target_std', 'atm_target_group_dist']\n",
    "\n",
    "data[new_atm_features] = pd.DataFrame(res)\n",
    "\n",
    "\n",
    "    \n",
    "for k in atm_k_values:\n",
    "    data['atm_dist_std_' + str(k)] = distances[:, 1:k].std(axis=1)\n",
    "\n",
    "for rad in atm_rad_values:\n",
    "    data['atm_dist_count_' + str(rad)] = (distances < rad).sum(axis=1)\n",
    "    \n",
    "    \n",
    "groups = data['group'].unique()\n",
    "\n",
    "for rad in tqdm_notebook(atm_group_rad_values):\n",
    "    res = []\n",
    "    for idx, row in enumerate(distances):\n",
    "        tmp = row < rad\n",
    "        cnt = Counter(data.loc[indexes[idx][tmp], 'group'].values)\n",
    "        m = tmp.sum()\n",
    "        res.append([cnt[el] / m for el in groups])\n",
    "        \n",
    "    data[[str(group) + str(rad) for group in groups]] = pd.DataFrame(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация признаков\n",
    "\n",
    "+ Количество банкоматов, имеющих такое сочетание группы + координат\n",
    "+ Количество банкоматов, имеющих такие же координаты\n",
    "+ Количество банкоматов, имеющих такой же ближайший <<избирательный город>>\n",
    "+ Количество банкоматов с такой же группой\n",
    "+ Количество банкоматов с таким же индексом избирательного адреса\n",
    "+ Тип локации избирательного участка (школа, театр, и т.п.). OHE\n",
    "+ Группа банкомата. OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating amount-related features')\n",
    "\n",
    "for name in ['coord']:\n",
    "    tmp = data.groupby([name, 'group']).size()\n",
    "    data[name + '_group_amount'] = data.apply(lambda x: tmp.get((x[name], x['group']), 0.), axis=1)\n",
    "for name in ['coord', 'group']:\n",
    "    data[name + '_amount'] = data[name].map(data.groupby(name).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, связанные с наиболее близким городом по таблице cities.csv\n",
    "\n",
    "Для каждого банкомата находится ближайший город из таблицы cities.csv\n",
    "\n",
    "Добавляется:\n",
    "+ Ближайший регион\n",
    "+ Ближайший город\n",
    "+ Население ближайшего города\n",
    "+ Расстояние до ближайшего города (фактически, расстояние до центра города"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating cities.csv features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/cities.csv\").rename({'Широта': 'lat', 'Долгота': 'lon'}, axis=1)\n",
    "\n",
    "coords = df[['lat', 'lon']].values\n",
    "neigh = NearestNeighbors()\n",
    "neigh.fit(coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, n_neighbors=100, return_distance=True)\n",
    "\n",
    "###\n",
    "\n",
    "data['city_dist'] = distances[:, 0]\n",
    "data['city_lat'] = df.loc[indexes[:, 0], 'lat'].values\n",
    "data['city_lon'] = df.loc[indexes[:, 0], 'lon'].values\n",
    "data['city_population'] = df.loc[indexes[:, 0], 'population']\\\n",
    "                            .apply(lambda x: re.findall('\\d+', x)[0]).astype(int).values\n",
    "\n",
    "data['city_region'] = df.loc[indexes[:, 0], 'region'].values\n",
    "data['city_town'] = df.loc[indexes[:, 0], 'town'].values\n",
    "data['city_region_type'] = df.loc[indexes[:, 0], 'Тип региона'].values\n",
    "data['city_district'] = df.loc[indexes[:, 0], 'Район'].values\n",
    "data['city_time'] = df.loc[indexes[:, 0], 'Часовой пояс'].values\n",
    "\n",
    "\n",
    "for name in ['town', 'region', 'region_type', 'district', 'time']:\n",
    "\n",
    "    tmp = data[['group', 'city_' + name]].groupby(['group', 'city_' + name]).size()\n",
    "    data['city_' + name + '_group_amount'] = data.apply(lambda x: tmp.get((x['group'], x['city_' + name]), 0.), axis=1)\n",
    "    \n",
    "    \n",
    "groups = data['group'].unique()\n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        data['city_' + name + '_group_' + str(group) + '_amount'] = data['city_' + name] \\\n",
    "                                                        .map(data.groupby('city_' + name)['group'] \\\n",
    "                                                        .apply(lambda x: (x == group).sum()))\n",
    "            \n",
    "###\n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in city_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "    \n",
    "city_diff_features = ['city_min_diff']\n",
    "for k in city_diff_k_values:\n",
    "    city_diff_features += ['city_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[city_diff_features] = pd.DataFrame(res)\n",
    "\n",
    "###\n",
    "\n",
    "important_coords = {\n",
    "    'moscow': [55.753879, 37.620373],\n",
    "    'peter': [59.939125, 30.315822]\n",
    "}\n",
    "\n",
    "for city in important_coords:\n",
    "    data['dist2' + city] = data[['lat', 'long']]\\\n",
    "                    .apply(lambda x: distance(important_coords[city], [x['lat'], x['long']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки по таблице плотности населения из statsdata\n",
    "\n",
    "+ Плотность населения региона, в котором стоит данный банкомат\n",
    "+ Население региона\n",
    "+ Площадь региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating population_statdata.csv features')\n",
    "\n",
    "\n",
    "statdata_df = pd.read_table('./data/prep/population_statdata.csv', delimiter=';').replace({'Москва': 'город Москва'})\n",
    "\n",
    "for name in statdata_df.columns[2 : -1]:\n",
    "    data[name] = data['izbir_region'].map(statdata_df.set_index('region')[name]).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки по населению из вики\n",
    "\n",
    "А именно, население по городам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating rus_cities_wiki.csv features')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/wiki_cities.csv\").drop_duplicates('town')\n",
    "\n",
    "data['wiki_town_population'] = data['izbir_town'].map(df.set_index('town')['population'])\n",
    "data['wiki_region_population'] = data['izbir_region'].map(lambda x: x.lower())\\\n",
    "                                .map(df.groupby('region')['population'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Признаки по населению из gks таблицы\n",
    "\n",
    "+ Только, собственно, еще одно населения региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating population_gks features')\n",
    "\n",
    "\n",
    "populus = pd.read_csv(\"./data/prep/population_gks.csv\")\n",
    "\n",
    "data['region_populus'] = data['izbir_region'].map(populus.set_index('region')['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Количество банкоматов Сбербанка в данном городе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating sberbank.csv features')\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_sberbank.csv\")\n",
    "\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index()\n",
    "coords = df[['lat', 'long']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = [(dists == 0.).sum()]\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in sber_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "sberbank_new_features = ['sberbank_zerodist_amount', 'sberbank_min_diff']\n",
    "for k in sber_diff_k_values:\n",
    "    sberbank_new_features += ['sberbank_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[sberbank_new_features] = pd.DataFrame(res)\n",
    "\n",
    "\n",
    "data['sberbank_dist'] = distances[:, 0]\n",
    "data['sberbank_lat'] = df.loc[indexes[:, 0], 'lat'].values\n",
    "data['sberbank_long'] = df.loc[indexes[:, 0], 'long'].values\n",
    "data['sberbank_index'] = df.loc[indexes[:, 0], 'Индекс'].astype(float).values\n",
    "\n",
    "\n",
    "data['sberbank_town'] = df.loc[indexes[:, 0], 'town'].values\n",
    "data['sberbank_subject'] = df.loc[indexes[:, 0], 'Субъект федерации'].values\n",
    "data['sberbank_type'] = df.loc[indexes[:, 0], 'Населенный пункт'].values\n",
    "data['sberbank_subtype'] = df.loc[indexes[:, 0], 'Улица'].values\n",
    "\n",
    "\n",
    "tmp = df['town'].dropna().map(lambda x: x.lower()).value_counts()\n",
    "data['sberbank_town_amount_outer'] = data['izbir_town'].map(tmp)\n",
    "\n",
    "for name in ['town', 'type', 'subject', 'subtype']:\n",
    "    tmp = data.groupby(['sberbank_' + name, 'group']).size()\n",
    "    data['sberbank_' + name + '_group_amount'] = data\\\n",
    "                .apply(lambda x: tmp.get((x['sberbank_' + name], x['group']), 0.), axis=1)\n",
    "        \n",
    "for name in ['town', 'type', 'subject', 'subtype']:\n",
    "    data['sberbank_' + name + '_amount'] = data['sberbank_' + name].map(data.groupby('sberbank_' + name).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки для точек из OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd520ad279b4d7b9a49a96aa0cddf57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6418), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info('creating OSM related features')\n",
    "\n",
    "\n",
    "with open('./data/prep/osm_data_0.005.pickle', 'rb') as fin:\n",
    "    osm_data = pickle.load(fin)\n",
    "\n",
    "osm_sections = {\n",
    " 'highway': ['crossing', 'traffic_signals', 'bus_stop'],\n",
    " 'crossing': ['uncontrolled', 'traffic_signals'],\n",
    " 'barrier': ['gate', 'lift_gate', 'block', 'entrance'],\n",
    " 'entrance': ['yes', 'main'],\n",
    " 'power': ['tower'],\n",
    " 'shop': ['convenience', 'supermarket', 'florist', 'hairdresser'],\n",
    " 'amenity': ['pharmacy', 'waste_disposal', 'parking', 'fountain', 'bench', 'cafe',\n",
    "            'car_wash', 'library', 'fuel', 'bank', 'toilets', 'fast_food'],\n",
    " 'traffic_calming': ['bump'],\n",
    " 'railway': ['level_crossing'],\n",
    " 'leisure': ['playground'],\n",
    " 'access': ['private'],\n",
    " 'natural': ['tree'],\n",
    " 'historic': ['memorial'],\n",
    " 'amenity': ['bank', 'atm'],\n",
    " 'name': ['Росбанк', 'Сбербанк', 'Газпромбанк', 'ВТБ', 'Россельхозбанк', 'Магнит', 'Пятёрочка']\n",
    "}\n",
    "\n",
    "feat = defaultdict(list)\n",
    "for coord in tqdm_notebook(osm_data):\n",
    "    for section in osm_sections:\n",
    "        nodes = [node for node in osm_data[coord] if section in node[1]]\n",
    "        \n",
    "        for subsection in osm_sections[section]:\n",
    "            curr_nodes = [node for node in nodes if node[1][section] == subsection]\n",
    "            if len(curr_nodes) > 0:\n",
    "                feat[coord] += [len(curr_nodes), curr_nodes[0][2]]\n",
    "                if len(curr_nodes) > 1:\n",
    "                    feat[coord] += [curr_nodes[1][2] - curr_nodes[1][2]]\n",
    "                else:\n",
    "                    feat[coord] += [1000]\n",
    "            else:\n",
    "                feat[coord] += [0, 1000, 1000]\n",
    "                \n",
    "osm_features = []\n",
    "for section in osm_sections:\n",
    "    for subsection in osm_sections[section]:\n",
    "        osm_features += [section + '_' + subsection + '_' + word for word in ['amount', 'min_dist', 'diff']]\n",
    "        \n",
    "data[osm_features] = pd.DataFrame(data['coord_idx'].map(feat).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зарплаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating fee-related features')\n",
    "\n",
    "# fee min\n",
    "fee_min = pd.read_csv(\"./data/prep/fee_min.csv\")\n",
    "for word in ['all', 'work', 'pension', 'child']:\n",
    "    data['fee_min_' + word] = data['izbir_region'].map(fee_min.set_index('region')['fee_' + word].map(np.log))\n",
    "data['fee_min_work2all'] = data['fee_min_work'] / data['fee_min_all']\n",
    "\n",
    "# fee work\n",
    "fee = pd.read_csv(\"./data/prep/fee_work.csv\").replace({'г.Москва': 'город Москва'})\n",
    "fee_names = fee.columns[1:]\n",
    "for field in fee_names:\n",
    "    data['fee_' + field] = data['izbir_region'].map(fee.set_index('region')[field].map(np.log)).fillna(0.).astype(float)\n",
    "    \n",
    "# fee avg\n",
    "#fee_avg = pd.read_csv(\"./data/prep/fees_avg.csv\")\n",
    "#data['fee_avg'] = data['izbir_town'].map(avg_fee.drop_duplicates('town').set_index('town').apply(np.log)['fee'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из банкоматов Росбанка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating rosbank_p2p.csv features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_rosbank_p2p.csv\")\n",
    "\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index(drop=True)\n",
    "coords = df[['lat', 'long']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data['rosbank_p2p_town'] = df.loc[indexes[:, 0], 'Город'].values\n",
    "data['rosbank_p2p_region'] = df.loc[indexes[:, 0], 'Регион'].values\n",
    "data['rosbank_p2p_regime'] = df.loc[indexes[:, 0], 'Режим работы'].values\n",
    "data['rosbank_p2p_address'] = df.loc[indexes[:, 0], 'address'].values\n",
    "\n",
    "data['rosbank_p2p_dist'] = distances[:, 0]\n",
    "data['rosbank_p2p_lat'] = df.loc[indexes[:, 0], 'lat'].values\n",
    "data['rosbank_p2p_long'] = df.loc[indexes[:, 0], 'long'].values\n",
    "\n",
    "for name in ['town', 'region', 'regime']:\n",
    "    tmp = data.groupby(['rosbank_p2p_' + name, 'group']).size()\n",
    "    data['rosbank_p2p_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x['rosbank_p2p_' + name], x['group']), 0.), axis=1).values\n",
    "    data['rosbank_p2p_' + name + '_amount'] = data['rosbank_p2p_' + name].map(data.groupby('rosbank_p2p_' + name).size())\n",
    "     \n",
    "    data['rosbank_p2p_' + name + '_rel'] = data['rosbank_p2p_' + name + '_group_amount'] / \\\n",
    "            data['rosbank_p2p_' + name + '_amount']\n",
    "        \n",
    "    \n",
    "rosbank_p2p_new_features = ['rosbank_p2p_min_diff']\n",
    "for k in rosbank_diff_k_values:\n",
    "    rosbank_p2p_new_features += ['rosbank_p2p_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in rosbank_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "data[rosbank_p2p_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Из банкоматов АТМ с сайта sravni.ru\n",
    "\n",
    "+ расстояние до ближайшего банкомата из этого списка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating sravni.ru features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_sravni_2.csv\")\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index(drop=True)\n",
    "\n",
    "coords = df[['lat', 'long']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data['sravni_dist'] = distances[:, 0]\n",
    "for name in ['bank', 'town', 'lat', 'long', 'service', 'time']:\n",
    "    data['sravni_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "for name in ['bank', 'town', 'service', 'time']:\n",
    "    tmp = data.groupby(['sravni_' + name, 'group']).size()\n",
    "    data['sravni_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x['sravni_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data['sravni_' + name + '_amount'] = data['sravni_' + name].map(data.groupby('sravni_' + name).size())   \n",
    "    \n",
    "    data['sravni_' + name + '_rel'] = data['sravni_' + name + '_group_amount'] / \\\n",
    "            data['sravni_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in sravni_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "sravni_new_features = ['sravni_min_diff']\n",
    "for k in sravni_diff_k_values:\n",
    "    sravni_new_features += ['sravni_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[sravni_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Россельхоз банк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating rosselhoz features')\n",
    "\n",
    "PREFIX = 'rshb'\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_rshb.csv\").rename({'location_lat': 'lat', 'location_lng': 'long'}, axis=1)\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index(drop=True)\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['region', 'lat', 'long', 'access', 'currency', 'shedule']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "for name in ['region', 'access', 'currency', 'shedule']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in rshb_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "rshb_new_features = [PREFIX + '_min_diff']\n",
    "for k in rshb_diff_k_values:\n",
    "    rshb_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[rshb_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Раффайзен банк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'raif'\n",
    "logging.info('creating raiffaizen features')\n",
    "             \n",
    "df = pd.read_csv(\"./data/prep/bank_raif.csv\")\n",
    "df['lat'] = np.array(df['coords'].apply(lambda x: json.loads(x)).tolist())[:, 0]\n",
    "df['long'] = np.array(df['coords'].apply(lambda x: json.loads(x)).tolist())[:, 1]\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['time', 'lat', 'long']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "    \n",
    "for name in ['time']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in raif_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "raif_new_features = [PREFIX + '_min_diff']\n",
    "for k in raif_diff_k_values:\n",
    "    raif_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[raif_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Газпромбанк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'gazprom'\n",
    "logging.info('creating gazprombank features')\n",
    "\n",
    "new_names = {\n",
    "    'GPS-координаты: широта': 'lat',\n",
    "    'GPS-координаты: долгота': 'long',\n",
    "    'Регион - имя собств.': 'region',\n",
    "    'Название населен. Пункта': 'town',\n",
    "    'Территориальное образование (регион) - суффикс': 'region_type', \n",
    "    'Город, поселок, село, …': 'town_type',\n",
    "    'Место расположения банкомата': 'loctype',\n",
    "    'Тип  (ATM / PVN / INF)': 'atm_type',\n",
    "    'Время работы / доступа': 'time', \n",
    "    'Visa / MC/ JCB / CUP': 'cards', \n",
    "    'Cash-IN': 'cash_in',\n",
    "    'Обмен валюты': 'exchange',\n",
    "    'Общий доступ': 'access',\n",
    "    'Банк / Филиал': 'bank'\n",
    "}\n",
    "\n",
    "df = pd.read_excel('./data/prep/bank_gazprombank.xlsx', header=1).rename(new_names, axis=1)\n",
    "df= df[~df[['lat', 'long']].isnull().any(axis=1)].copy()\n",
    "\n",
    "\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['town', 'region', 'lat', 'long', 'region_type', 'town_type', 'loctype', 'atm_type',\n",
    "            'cards', 'access']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "    \n",
    "for name in ['region', 'town', 'region_type', 'town_type', 'loctype', 'atm_type', 'cards', 'access']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in gazprom_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "gazprom_new_features = [PREFIX + '_min_diff']\n",
    "for k in gazprom_diff_k_values:\n",
    "    gazprom_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[gazprom_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Росбанк и партнеры (сайт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'partners'\n",
    "logging.info('creating partners features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_rosbank.csv\")\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index()\n",
    "\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 10, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "###\n",
    "\n",
    "for name in ['bank', 'region', 'location']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "    \n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in partners_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "partners_new_features = [PREFIX + '_min_diff']\n",
    "for k in partners_diff_k_values:\n",
    "    partners_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[partners_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "group2name = {\n",
    "    496.5: 'Россельхозбанк', 1022.0: 'Ак Барс',\n",
    "    1942.0: 'Альфа-Банк', 3185.5: 'Газпромбанк',\n",
    "    5478.0: 'Уралсиб', 8083.0: 'Росбанк'\n",
    "}\n",
    "\n",
    "atms = pd.read_csv(\"./data/prep/bank_sravni_2.csv\")\n",
    "data['group_bank'] = data['group'].map(group2name)\n",
    "\n",
    "tmp = atms.groupby(['town', 'bank']).size()\n",
    "data['atms_town_group_bank_amount'] = data.apply(lambda x: tmp.get((x['izbir_town'], x['group_bank']), 0.), axis=1)\n",
    "data['izbir_atm_town'] = data['izbir_town'].map(atms.groupby('town').size())\n",
    "data['group_bank_amount'] = data['group_bank'].map(atms.groupby('bank').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Список получаемых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features_dict = defaultdict(list)\n",
    "\n",
    "\n",
    "# initial features\n",
    "features += ['id', 'loc_null', 'izbir_idx', 'lat', 'long', 'izbir_voters_in', 'izbir_voters_out', 'izbir_dist']\n",
    "for name in ['coord', 'izbir_town', 'izbir_region', 'izbir_type', 'izbir_location_type']:\n",
    "    features += [name + '_group_amount']\n",
    "for name in ['coord', 'izbir_town', 'izbir_region', 'group', 'izbir_address']:\n",
    "    features += [name + '_amount']\n",
    "    \n",
    "features_dict['initial'] += features\n",
    "\n",
    "# metro_features\n",
    "\n",
    "for filename in metro_fields:\n",
    "    features += [filename + '_' + word for word in ['dist', 'lat', 'lon']]\n",
    "    features_dict['metro'] += [filename + '_' + word for word in ['dist', 'lat', 'lon']]\n",
    "    for name in metro_fields[filename]:\n",
    "        features += [filename + '_' + name + '_group_amount']\n",
    "        features_dict['metro'] += [filename + '_' + name + '_group_amount']\n",
    "    features += [filename + '_' + word for word in metro_new_features]\n",
    "    features_dict['metro'] += [filename + '_' + word for word in metro_new_features]\n",
    "    for rad in metro_rad_values:\n",
    "        features += [filename + '_dist_count_' + str(rad)]\n",
    "        features_dict['metro'] += [filename + '_dist_count_' + str(rad)]\n",
    "    \n",
    "# atm features\n",
    "features += new_atm_features\n",
    "features_dict['atm'] += new_atm_features\n",
    "for k in atm_k_values:\n",
    "    features += ['atm_dist_std_' + str(k)]\n",
    "    features_dict['atm'] += ['atm_dist_std_' + str(k)]\n",
    "for rad in atm_rad_values:\n",
    "    features += ['atm_dist_count_' + str(rad)]\n",
    "    features_dict['atm'] += ['atm_dist_count_' + str(rad)]\n",
    "for rad in atm_group_rad_values:\n",
    "    features += [str(group) + str(rad) for group in groups]\n",
    "    features_dict['atm'] += [str(group) + str(rad) for group in groups]\n",
    "\n",
    "# cities.csv\n",
    "features += ['city_dist', 'city_lat', 'city_lon', 'city_population']\n",
    "features_dict['city'] += ['city_dist', 'city_lat', 'city_lon', 'city_population']\n",
    "\n",
    "for name in ['town', 'region', 'region_type', 'district', 'time']:\n",
    "    features += ['city_' + name + '_group_amount']\n",
    "    features_dict['city'] += ['city_' + name + '_group_amount']\n",
    "    \n",
    "for city in important_coords:\n",
    "    features += ['dist2' + city]\n",
    "    features_dict['city'] += ['dist2' + city]\n",
    "    \n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        features += ['city_' + name + '_group_' + str(group) + '_amount']\n",
    "        features_dict['city'] += ['city_' + name + '_group_' + str(group) + '_amount']\n",
    "        \n",
    "features += city_diff_features\n",
    "features_dict['city'] += city_diff_features\n",
    "\n",
    "###### opendata\n",
    "#for name in opendata_df['name'].unique():\n",
    "#    features += [name]\n",
    "# for name in opendata_df['name'].unique():\n",
    "#     features += [name + '_' + word for word in opendata_words]\n",
    "#     features_dict['opendata'] += [name + '_' + word for word in opendata_words]\n",
    "    \n",
    "###### statdata\n",
    "# for name in statdata_df.columns[2 : -1]:\n",
    "#     features += [name]\n",
    "#     features_dict['statdata'] += [name]\n",
    "    \n",
    "# rus cities wiki, gks_table\n",
    "\n",
    "features += ['region_populus', 'wiki_town_population', 'wiki_region_population']\n",
    "features_dict['populus'] += ['region_populus', 'wiki_town_population', 'wiki_region_population']\n",
    "\n",
    "# sberbank xls\n",
    "\n",
    "features += ['sberbank_lat', 'sberbank_long', 'sberbank_index']\n",
    "features_dict['sberbank'] +=['sberbank_lat', 'sberbank_long', 'sberbank_index']\n",
    "\n",
    "features += ['sberbank_' + word for word in ['dist', 'town_amount_outer']]\n",
    "features_dict['sberbank'] += ['sberbank_' + word for word in ['dist', 'town_amount_outer']]\n",
    "\n",
    "for name in ['town', 'type', 'subject', 'subtype']:\n",
    "    features += ['sberbank_' + name + '_group_amount']\n",
    "    features_dict['sberbank'] += ['sberbank_' + name + '_group_amount']\n",
    "    \n",
    "for name in ['town', 'type', 'subject']:\n",
    "    features += ['sberbank_' + name + '_amount']\n",
    "    features_dict['sberbank'] += ['sberbank_' + name + '_amount']\n",
    "    \n",
    "features += sberbank_new_features\n",
    "features_dict['sberbank'] += sberbank_new_features\n",
    "\n",
    "# OSM\n",
    "features += osm_features\n",
    "features_dict['osm'] = osm_features\n",
    "# fees\n",
    "\n",
    "features += ['fee_min_work2all']\n",
    "features_dict['initial'] += ['fee_min_work2all']\n",
    "\n",
    "#for field in fee_names:\n",
    "#    features += ['fee_' + field]\n",
    "#    features_dict['fee'] += ['fee_' + field]\n",
    "#features += ['fee_avg']\n",
    "\n",
    "# банкоматы с sravni.ru\n",
    "\n",
    "features += ['sravni_dist', 'sravni_lat', 'sravni_long']\n",
    "features_dict['sravni'] += ['sravni_dist', 'sravni_lat', 'sravni_long']\n",
    "\n",
    "for name in ['bank', 'town', 'service', 'time']:\n",
    "    features += ['sravni_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    features_dict['sravni'] += ['sravni_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    \n",
    "features += sravni_new_features\n",
    "features_dict['sravni'] += sravni_new_features\n",
    "\n",
    "# банкоматы росбанка\n",
    "\n",
    "features += ['rosbank_p2p_dist', 'rosbank_p2p_lat', 'rosbank_p2p_long']\n",
    "features_dict['rosbank_p2p'] += ['rosbank_p2p_dist', 'rosbank_p2p_lat', 'rosbank_p2p_long']\n",
    "\n",
    "for name in ['town', 'region', 'regime']:\n",
    "    features += ['rosbank_p2p_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    features_dict['rosbank_p2p'] += ['rosbank_p2p_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    \n",
    "features += rosbank_p2p_new_features\n",
    "features_dict['rosbank_p2p'] += rosbank_p2p_new_features\n",
    "    \n",
    "# россельхоз банк\n",
    "PREFIX = 'rshb'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['region', 'access', 'currency', 'shedule']:\n",
    "    features += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "features += rshb_new_features\n",
    "features_dict[PREFIX] += rshb_new_features\n",
    "\n",
    "# raiffaizen\n",
    "PREFIX = 'raif'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['time']:\n",
    "    features += [PREFIX + '_' + name + '_group_amount']\n",
    "    features += [PREFIX + '_' + name + '_amount']\n",
    "    features += [PREFIX + '_' + name + '_rel']\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    \n",
    "features += raif_new_features\n",
    "features_dict[PREFIX] += raif_new_features\n",
    "\n",
    "# gazprombank\n",
    "PREFIX = 'gazprom'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['region', 'town', 'region_type', 'town_type', 'loctype', 'atm_type', 'cards', 'access']:\n",
    "    features += [PREFIX + '_' + name + '_group_amount']\n",
    "    features += [PREFIX + '_' + name + '_amount']\n",
    "    features += [PREFIX + '_' + name + '_rel']\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    \n",
    "features += gazprom_new_features\n",
    "features_dict[PREFIX] += gazprom_new_features\n",
    "\n",
    "# partners\n",
    "PREFIX = 'partners'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist']]\n",
    "\n",
    "for name in ['bank', 'region', 'location']:\n",
    "    features += [PREFIX + '_' + name + '_group_amount']\n",
    "    features += [PREFIX + '_' + name + '_amount']\n",
    "    features += [PREFIX + '_' + name + '_rel']\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    \n",
    "features += partners_new_features\n",
    "features_dict[PREFIX] += partners_new_features\n",
    "\n",
    "features += ['atms_town_group_bank_amount', 'izbir_atm_town', 'group_bank_amount']\n",
    "features_dict[PREFIX] += ['atms_town_group_bank_amount', 'izbir_atm_town', 'group_bank_amount']\n",
    "#########\n",
    "logging.info('Result: {} features'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HOLDOUT_MODE:\n",
    "\n",
    "    data.to_csv('./data/prep_data_old_HO.csv', index=False)\n",
    "    np.save('./data/prep_features_old_HO.npy', features)\n",
    "    np.save('./data/prep_features_dict_old_HO.npy', features_dict)\n",
    "    \n",
    "else:\n",
    "    data.to_csv('./data/prep_data_old.csv', index=False)\n",
    "    np.save('./data/prep_features_old.npy', features)\n",
    "    np.save('./data/prep_features_dict_old.npy', features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial 19\n",
      "metro 38\n",
      "atm 39\n",
      "city 25\n",
      "populus 3\n",
      "sberbank 20\n",
      "osm 93\n",
      "sravni 22\n",
      "rosbank_p2p 19\n",
      "rshb 22\n",
      "raif 13\n",
      "gazprom 34\n",
      "partners 20\n"
     ]
    }
   ],
   "source": [
    "for el in features_dict:\n",
    "    print(el, len(features_dict[el]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
