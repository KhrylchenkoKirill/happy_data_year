{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начиная отсюда, можно все запускать\n",
    "\n",
    "Здесь происходит финальная предобработка фич.\n",
    "\n",
    "В следующем ноутбуке будет старая предобработка, тоже используемая для финальной модели.\n",
    "\n",
    "Результаты обеих предобработок на всякий случай уже сохранены и лежат в папке ./data/created_files\n",
    "\n",
    "В целом один ноутбук предобработки занимает не более 20-30 минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import re, pickle, logging, json, gc, utils\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "from tqdm import tqdm_notebook\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "R = 6373.0 # радиус земли в километрах\n",
    "\n",
    "def distance(x, y):\n",
    "    lat_a, long_a, lat_b, long_b = map(radians, [*x,*y])  \n",
    "    dlon = long_b - long_a\n",
    "    dlat = lat_b - lat_a\n",
    "    a = sin(0.5 * dlat)**2 + cos(lat_a) * cos(lat_b) * sin(0.5 * dlon)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "HOLDOUT_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_k_values = []\n",
    "atm_rad_values = [1]\n",
    "atm_group_rad_values = [1]\n",
    "metro_rad_values=[1.]\n",
    "\n",
    "metro_diff_k_values = [10, 50]\n",
    "sber_diff_k_values = [10, 100]\n",
    "atm_diff_k_values = [15, 100]\n",
    "city_diff_k_values = [10, 100]\n",
    "rosbank_diff_k_values = [10, 100]\n",
    "sravni_diff_k_values = [10, 100]\n",
    "rshb_diff_k_values = [10, 50]\n",
    "raif_diff_k_values = [10, 50]\n",
    "gazprom_diff_k_values = [10, 50]\n",
    "partners_diff_k_values = [10, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='./data/logs/logfile.log', level=logging.INFO, \n",
    "                    format='%(asctime)s %(message)s', datefmt='%I:%M:%S. ')\n",
    "logging.info('Reading data.csv')\n",
    "\n",
    "data = pd.read_csv(\"./data/prep/data.csv\")\n",
    "groups = data['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# holdout mode\n",
    "if HOLDOUT_MODE:\n",
    "    holdout = range(5009, 6261)\n",
    "\n",
    "    data['isHoldout'] = [el in holdout for el in range(data.shape[0])]\n",
    "    data.loc[holdout, 'isTrain'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Избирательные участки\n",
    "\n",
    "+ Расстояние до ближайшего участка\n",
    "+ Широта и долгота ближайшего участка\n",
    "+ Для типа, региона, города, типа объекта, и адреса ближайшего участка считаются признаки:\n",
    "  + Количество объектов в выборке с такой же категорией (с таким же городом, регионом и т.п.)\n",
    "  + Количество объектов с такой же категорией и такой же группой, как и у объекта, для которого считается признак\n",
    "  + отношение второй величины к первой, то есть доля объектов с такой же группой среди всех объектов данной категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.4 s, sys: 525 ms, total: 51.9 s\n",
      "Wall time: 51.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "votes = pd.read_csv(\"./data/prep/votes.csv\")\n",
    "coords = votes[['lat', 'lon']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "    \n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 2, return_distance=True)\n",
    "\n",
    "PREFIX = 'izbir'\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['lat', 'lon', 'type', 'region', 'location_type', 'town', 'voters_in', 'voters_out', 'idx', 'address']:\n",
    "    data[PREFIX + '_' + name] = votes.loc[indexes[:, 0], name].values\n",
    "    \n",
    "for name in ['type', 'region', 'location_type', 'town', 'address']:\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        data[PREFIX + '_' + name + '_group_' + str(group) + '_amount'] = data[PREFIX + '_' + name] \\\n",
    "                            .map(data.groupby(PREFIX + '_' + name)['group'] \\\n",
    "                            .apply(lambda x: (x == group).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, связанные с наиболее близким городом по таблице cities.csv\n",
    "\n",
    "+ Расстояние до ближайшего города (фактически до центра города)\n",
    "+ Широта и долгота данного города\n",
    "+ Население города\n",
    "+ Широта и долгота ближайшего участка\n",
    "+ Для города, региона, типа региона, района и часового пояса ближайшего города считаются признаки:\n",
    "  + Количество объектов в выборке с такой же категорией (с таким же городом, регионом и т.п.)\n",
    "  + Количество объектов с такой же категорией и такой же группой, как и у объекта, для которого считается признак\n",
    "  + отношение второй величины к первой, то есть доля объектов с такой же группой среди всех объектов данной категории\n",
    "+ Расстояние до Москвы и Питера\n",
    "+ Количество объектов каждой из групп в данном городе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.89 s, sys: 52 ms, total: 4.95 s\n",
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "city_renames = {\n",
    "    'Широта': 'lat',\n",
    "    'Долгота': 'lon',\n",
    "    'Тип региона': 'region_type',\n",
    "    'Район': 'district',\n",
    "    'Часовой пояс': 'time'\n",
    "}\n",
    "\n",
    "logging.info('creating cities.csv features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/cities.csv\").rename(city_renames, axis=1)\n",
    "\n",
    "coords = df[['lat', 'lon']].values\n",
    "neigh = NearestNeighbors()\n",
    "neigh.fit(coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, n_neighbors=100, return_distance=True)\n",
    "\n",
    "PREFIX = 'city'\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "data['city_population'] = df.loc[indexes[:, 0], 'population']\\\n",
    "                            .apply(lambda x: re.findall('\\d+', x)[0]).astype(int).values\n",
    "\n",
    "for name in ['lat', 'lon', 'region', 'town', 'region_type', 'district', 'time']:\n",
    "    data[PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "data['city_town'] = data['city_town'].map(lambda x: x.lower() if x == x else x)\n",
    "data.loc[data['city_region'] == 'Москва'] == 'москва'\n",
    "data['city_region'].replace({'Москва': 'город Москва'}, inplace=True)\n",
    "data.loc[data['city_region'] == 'Санкт-Петербург'] == 'санкт-петербург'\n",
    "data['city_region'].replace({'Санкт-Петербург': 'город Санкт-Петербург'}, inplace=True)\n",
    "\n",
    "for name in ['town', 'region', 'region_type', 'district', 'time']:\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        data[PREFIX + '_' + name + '_group_' + str(group) + '_amount'] = data[PREFIX + '_' + name] \\\n",
    "                            .map(data.groupby(PREFIX + '_' + name)['group'] \\\n",
    "                            .apply(lambda x: (x == group).sum()))\n",
    "            \n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in city_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "city_diff_features = [PREFIX + '_min_diff']\n",
    "for k in city_diff_k_values:\n",
    "    city_diff_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "data[city_diff_features] = pd.DataFrame(res)\n",
    "\n",
    "important_coords = {\n",
    "    'moscow': [55.753879, 37.620373],\n",
    "    'peter': [59.939125, 30.315822]\n",
    "}\n",
    "\n",
    "for city in important_coords:\n",
    "    data['dist2' + city] = data[['lat', 'long']]\\\n",
    "                    .apply(lambda x: distance(important_coords[city], [x['lat'], x['long']]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, связанные с метро\n",
    "\n",
    "+ Расстояние до ближайшей станции метро\n",
    "+ Количество станций в радиусе одного км"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70d530ce07448a984d8b048abcc451e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79a94ad84f04ecba777ad65f63c8a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84375daa0eb74d9d957db5f58cc0f26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "CPU times: user 14.7 s, sys: 334 ms, total: 15.1 s\n",
      "Wall time: 15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logging.info('creating metro features')\n",
    "\n",
    "metro_fields = {\n",
    "    'metro': ['town', 'line', 'station'],\n",
    "    'metro_moscow': ['station'],\n",
    "    'metro_peter': ['station']\n",
    "}\n",
    "\n",
    "metro_new_features = []\n",
    "metro_new_features += ['min_diff']\n",
    "for k in metro_diff_k_values:\n",
    "    metro_new_features += ['diff_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "\n",
    "for filename in metro_fields:\n",
    "    df = pd.read_csv(\"./data/prep/\" + filename + \".csv\")\n",
    "    coords = df[['lat', 'lon']].values\n",
    "    neigh = NearestNeighbors(metric=distance)\n",
    "    neigh.fit(coords)\n",
    "    \n",
    "    distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 50, return_distance=True)\n",
    "    \n",
    "    data[filename + '_dist'] = distances[:, 0]\n",
    "    data[filename + '_lat'] = df.loc[indexes[:, 0], 'lat'].values\n",
    "    data[filename + '_lon'] = df.loc[indexes[:, 0], 'lon'].values\n",
    "\n",
    "    PREFIX = filename\n",
    "    for name in metro_fields[filename]:\n",
    "        \n",
    "        data[PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "        \n",
    "        data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "        tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "        data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "            data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "\n",
    "        data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "                data[PREFIX + '_' + name + '_amount']\n",
    "            \n",
    "    stats = []\n",
    "    for idx, (dists, ids) in tqdm_notebook(enumerate(zip(distances, indexes)), leave=False):\n",
    "        info = []\n",
    "        diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "        info.append(diffs[0])\n",
    "        for k in metro_diff_k_values:\n",
    "            info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "        stats.append(info)\n",
    "    data[[filename + '_' + word for word in metro_new_features]] = pd.DataFrame(stats)\n",
    "    \n",
    "    for rad in metro_rad_values:\n",
    "        data[filename + '_dist_count_' + str(rad)] = (distances < rad).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOWN = 'izbir_town'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки по населению из вики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating wiki.csv features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/wiki_cities.csv\").drop_duplicates('town')\n",
    "\n",
    "data['wiki_town_population'] = data[TOWN].map(df.set_index('town')['population'])\n",
    "data['wiki_region_population'] = data['izbir_region'].map(lambda x: x.lower())\\\n",
    "                                .map(df.groupby('region')['population'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки по населению из gks таблицы\n",
    "\n",
    "+ Только, собственно, еще одно населения региона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating population_gks features')\n",
    "\n",
    "\n",
    "populus = pd.read_csv(\"./data/prep/population_gks.csv\")\n",
    "\n",
    "data['gks_population'] = data['izbir_region'].map(populus.set_index('region')['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зарплаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating fee-related features')\n",
    "\n",
    "# fee min\n",
    "fee_min = pd.read_csv(\"./data/prep/fee_min.csv\")\n",
    "for word in ['all', 'work', 'pension', 'child']:\n",
    "    data['fee_min_' + word] = data['izbir_region'].map(fee_min.set_index('region')['fee_' + word].map(np.log))\n",
    "data['fee_min_work2all'] = data['fee_min_work'] / data['fee_min_all']\n",
    "\n",
    "# fee work\n",
    "fee = pd.read_csv(\"./data/prep/fee_work.csv\").replace({'г.Москва': 'город Москва'})\n",
    "fee_names = fee.columns[1:]\n",
    "for field in fee_names:\n",
    "    data['fee_' + field] = data['izbir_region'].map(fee.set_index('region')[field].map(np.log)).fillna(0.).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Генерация признаков\n",
    "\n",
    "+ Количество банкоматов, имеющих такое сочетание группы + координат\n",
    "+ Количество банкоматов, имеющих такие же координаты\n",
    "+ Количество банкоматов, имеющих такой же ближайший <<избирательный город>>\n",
    "+ Количество банкоматов с такой же группой\n",
    "+ Количество банкоматов с таким же индексом избирательного адреса\n",
    "+ Тип локации избирательного участка (школа, театр, и т.п.). OHE\n",
    "+ Группа банкомата. OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'initial'\n",
    "\n",
    "for name in ['coord']:\n",
    "    data[PREFIX + '_' + name + '_amount'] = data[name].map(data.groupby(name).size())\n",
    "    \n",
    "    tmp = data.groupby([name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[name], x['group']), 0.), axis=1).values\n",
    "\n",
    "    #data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "     #           data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "        \n",
    "data['group_amount'] = data['group'].map(data.groupby('group').size())\n",
    "\n",
    "for name in ['coord']:\n",
    "    for group in groups:\n",
    "        data[PREFIX + '_' + name + '_group_' + str(group) + '_amount'] = \\\n",
    "            data[name].map(data.groupby(name)['group'].apply(lambda x: (x == group).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признаки, связанные с банкоматами из выборки\n",
    "\n",
    "+ Расстояние до ближайшего другого банкомата\n",
    "+ Количество банкоматов в радиусах 0.05, 0.1, 0.3, 0.5, 1\n",
    "+ Стандартное отклонение расстояний до самых близких 40 банкоматов\n",
    "+ Доля банкоматов из той или иной группы в радиусах 0.1, 0.5, 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating atm related features')\n",
    "\n",
    "data_coords = data[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(data_coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8497f0dcaec44b8b9a5c9f454d85d54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for idx, (dists, ids) in tqdm_notebook(enumerate(zip(distances, indexes))):\n",
    "    \n",
    "    info = []\n",
    "    \n",
    "    curr_group = data.loc[idx, 'group']\n",
    "    curr_dists = dists[ids != idx]\n",
    "    min_dist = curr_dists[0]\n",
    "    curr_ids = ids[ids != idx]\n",
    "    \n",
    "    min_ids = curr_ids[curr_dists == min_dist]\n",
    "    n = len(min_ids)\n",
    "    info.append(n)\n",
    "    cnt = data.loc[min_ids, 'group'].value_counts()\n",
    "    group_counts = [cnt.get(group, 0) / n for group in groups]\n",
    "    info += group_counts\n",
    "    tmp = np.array(group_counts)\n",
    "    info += [(tmp[tmp != 0] * np.log(tmp[tmp != 0])).sum()]\n",
    "    info.append(min_dist)\n",
    "    \n",
    "    if min_dist == 0:\n",
    "        info.append(1)\n",
    "    else:\n",
    "        info.append(0)\n",
    "\n",
    "    for k in atm_diff_k_values:\n",
    "        curr_k_dists = curr_dists[:k]\n",
    "        diffs = [curr_k_dists[i + 1] - curr_k_dists[i] for i in range(len(curr_k_dists) - 1)]\n",
    "        if len(diffs) > 0:\n",
    "            info += [np.mean(diffs), np.max(diffs), np.std(diffs)]\n",
    "        else:\n",
    "            info += [0] * 3\n",
    "        \n",
    "    for group in groups:\n",
    "        mask = data.loc[curr_ids, 'group'] == group\n",
    "        \n",
    "        if mask.sum() == 0:\n",
    "            info += [0] * 2\n",
    "        else:\n",
    "            curr_group_ids = curr_ids[mask]\n",
    "            curr_group_dists = curr_dists[mask]\n",
    "\n",
    "            min_group_dist = curr_group_dists[0]\n",
    "            min_group_ids = curr_group_ids[curr_group_dists == min_group_dist]\n",
    "            group_n = len(min_group_ids)\n",
    "            info.append(group_n)\n",
    "            info.append(min_group_dist)\n",
    "    \n",
    "    res.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "596cb9e906e94eefa0521c2a99c76466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_atm_features = ['atm_min_len'] + ['atm_min_freq_' + str(group) for group in groups] + ['group_entropy']\n",
    "new_atm_features += ['atm_min_dist', 'atm_min_is_0']\n",
    "for k in atm_diff_k_values:\n",
    "    new_atm_features += ['atm_diff_' + str(k) + '_' + word for word in ['mean' ,'max', 'std']]\n",
    "for group in groups:\n",
    "    new_atm_features += ['atm_min_group_len_' + str(group), 'atm_min_group_dist_' + str(group)]\n",
    "\n",
    "data[new_atm_features] = pd.DataFrame(res)\n",
    "\n",
    "\n",
    "    \n",
    "for k in atm_k_values:\n",
    "    data['atm_dist_std_' + str(k)] = distances[:, 1:k].std(axis=1)\n",
    "\n",
    "for rad in atm_rad_values:\n",
    "    data['atm_dist_count_' + str(rad)] = (distances < rad).sum(axis=1)\n",
    "    \n",
    "    \n",
    "groups = data['group'].unique()\n",
    "\n",
    "for rad in tqdm_notebook(atm_group_rad_values):\n",
    "    res = []\n",
    "    for idx, row in enumerate(distances):\n",
    "        tmp = row < rad\n",
    "        cnt = Counter(data.loc[indexes[idx][tmp], 'group'].values)\n",
    "        m = tmp.sum()\n",
    "        res.append([cnt[el] / m for el in groups])\n",
    "        \n",
    "    data[[str(group) + str(rad) for group in groups]] = pd.DataFrame(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09e84d50ebc4bd99ec469e0834a7831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6418), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "logging.info('creating OSM related features')\n",
    "\n",
    "\n",
    "with open('./data/prep/osm_data_0.005.pickle', 'rb') as fin:\n",
    "    osm_data = pickle.load(fin)\n",
    "\n",
    "osm_sections = {\n",
    " 'highway': ['crossing', 'traffic_signals', 'bus_stop'],\n",
    " 'crossing': ['uncontrolled', 'traffic_signals'],\n",
    " 'barrier': ['gate', 'lift_gate', 'block', 'entrance'],\n",
    " 'entrance': ['yes', 'main'],\n",
    " 'power': ['tower'],\n",
    " 'shop': ['convenience', 'supermarket', 'florist', 'hairdresser'],\n",
    " 'amenity': ['pharmacy', 'waste_disposal', 'parking', 'fountain', 'bench', 'cafe',\n",
    "            'car_wash', 'library', 'fuel', 'bank', 'toilets', 'fast_food'],\n",
    " 'traffic_calming': ['bump'],\n",
    " 'railway': ['level_crossing'],\n",
    " 'leisure': ['playground'],\n",
    " 'access': ['private'],\n",
    " 'natural': ['tree'],\n",
    " 'historic': ['memorial'],\n",
    " 'amenity': ['bank', 'atm'],\n",
    " 'name': ['Росбанк', 'Сбербанк', 'Газпромбанк', 'ВТБ', 'Россельхозбанк', 'Магнит', 'Пятёрочка']\n",
    "}\n",
    "\n",
    "feat = defaultdict(list)\n",
    "for coord in tqdm_notebook(osm_data):\n",
    "    for section in osm_sections:\n",
    "        nodes = [node for node in osm_data[coord] if section in node[1]]\n",
    "        \n",
    "        for subsection in osm_sections[section]:\n",
    "            curr_nodes = [node for node in nodes if node[1][section] == subsection]\n",
    "            if len(curr_nodes) > 0:\n",
    "                feat[coord] += [len(curr_nodes), curr_nodes[0][2]]\n",
    "                if len(curr_nodes) > 1:\n",
    "                    feat[coord] += [curr_nodes[1][2] - curr_nodes[1][2]]\n",
    "                else:\n",
    "                    feat[coord] += [1000]\n",
    "            else:\n",
    "                feat[coord] += [0, 1000, 1000]\n",
    "                \n",
    "osm_features = []\n",
    "for section in osm_sections:\n",
    "    for subsection in osm_sections[section]:\n",
    "        osm_features += [section + '_' + subsection + '_' + word for word in ['amount', 'min_dist', 'diff']]\n",
    "        \n",
    "data[osm_features] = pd.DataFrame(data['coord_idx'].map(feat).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сбербанк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating sberbank.csv features')\n",
    "\n",
    "sberbank_renames = {\n",
    "    'Субъект федерации': 'region',\n",
    "    'Населенный пункт': 'type',\n",
    "    'Улица': 'district',\n",
    "    'Индекс': 'index'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_sberbank.csv\").rename(sberbank_renames, axis=1)\n",
    "\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index()\n",
    "coords = df[['lat', 'long']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = [(dists == 0.).sum()]\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in sber_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "PREFIX = 'sberbank'\n",
    "\n",
    "sberbank_new_features = [PREFIX + '_zerodist_amount', PREFIX + '_min_diff']\n",
    "for k in sber_diff_k_values:\n",
    "    sberbank_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[sberbank_new_features] = pd.DataFrame(res)\n",
    "\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "for name in ['lat', 'long', 'index', 'town', 'region', 'type', 'district']:\n",
    "    \n",
    "    if name == 'index':\n",
    "        data[PREFIX + '_index'] = df.loc[indexes[:, 0], 'index'].astype(float).values\n",
    "    else:\n",
    "        data[PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "\n",
    "tmp = df['town'].dropna().map(lambda x: x.lower()).value_counts()\n",
    "data[PREFIX + '_town_amount_outer'] = data[TOWN].map(tmp)\n",
    "\n",
    "for name in ['town', 'type', 'region', 'district']:\n",
    "    \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())\n",
    "    \n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = data\\\n",
    "                .apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1)\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "                data[PREFIX + '_' + name + '_amount']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rosbank p2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating rosbank_p2p.csv features')\n",
    "\n",
    "rosbank_p2p_renames = {\n",
    "    'Город': 'town',\n",
    "    'Регион': 'region',\n",
    "    'Режим работы': 'regime',\n",
    "}\n",
    "df = pd.read_csv(\"./data/prep/bank_rosbank_p2p.csv\").rename(rosbank_p2p_renames, axis=1)\n",
    "\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index(drop=True)\n",
    "coords = df[['lat', 'long']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data['rosbank_p2p_dist'] = distances[:, 0]\n",
    "\n",
    "PREFIX = 'rosbank_p2p'\n",
    "for name in ['town', 'region', 'regime', 'address', 'lat', 'long']:\n",
    "    data[PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "for name in ['town', 'region', 'regime']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())\n",
    "     \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX+ '_' + name + '_amount']\n",
    "        \n",
    "    \n",
    "rosbank_p2p_new_features = [PREFIX + '_min_diff']\n",
    "for k in rosbank_diff_k_values:\n",
    "    rosbank_p2p_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "\n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in rosbank_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "data[rosbank_p2p_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sravni.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating sravni.ru features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_sravni_2.csv\")\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index(drop=True)\n",
    "\n",
    "coords = df[['lat', 'long']].values\n",
    "\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "PREFIX = 'sravni'\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "for name in ['bank', 'town', 'lat', 'long', 'service', 'time']:\n",
    "    data[PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "for name in ['bank', 'town', 'service', 'time']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x['sravni_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in sravni_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "sravni_new_features = [PREFIX + '_min_diff']\n",
    "for k in sravni_diff_k_values:\n",
    "    sravni_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[sravni_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Россельхозбанк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info('creating rosselhoz features')\n",
    "\n",
    "PREFIX = 'rshb'\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_rshb.csv\").rename({'location_lat': 'lat', 'location_lng': 'long'}, axis=1)\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index(drop=True)\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['region', 'lat', 'long', 'access', 'currency', 'shedule']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "\n",
    "for name in ['region', 'access', 'currency', 'shedule']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in rshb_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "rshb_new_features = [PREFIX + '_min_diff']\n",
    "for k in rshb_diff_k_values:\n",
    "    rshb_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[rshb_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Раффайзен банк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'raif'\n",
    "logging.info('creating raiffaizen features')\n",
    "             \n",
    "df = pd.read_csv(\"./data/prep/bank_raif.csv\")\n",
    "df['lat'] = np.array(df['coords'].apply(lambda x: json.loads(x)).tolist())[:, 0]\n",
    "df['long'] = np.array(df['coords'].apply(lambda x: json.loads(x)).tolist())[:, 1]\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['time', 'lat', 'long']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "    \n",
    "for name in ['time']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in raif_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "raif_new_features = [PREFIX + '_min_diff']\n",
    "for k in raif_diff_k_values:\n",
    "    raif_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[raif_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Газпромбанк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'gazprom'\n",
    "logging.info('creating gazprombank features')\n",
    "\n",
    "new_names = {\n",
    "    'GPS-координаты: широта': 'lat',\n",
    "    'GPS-координаты: долгота': 'long',\n",
    "    'Регион - имя собств.': 'region',\n",
    "    'Название населен. Пункта': 'town',\n",
    "    'Территориальное образование (регион) - суффикс': 'region_type', \n",
    "    'Город, поселок, село, …': 'town_type',\n",
    "    'Место расположения банкомата': 'loctype',\n",
    "    'Тип  (ATM / PVN / INF)': 'atm_type',\n",
    "    'Время работы / доступа': 'time', \n",
    "    'Visa / MC/ JCB / CUP': 'cards', \n",
    "    'Cash-IN': 'cash_in',\n",
    "    'Обмен валюты': 'exchange',\n",
    "    'Общий доступ': 'access',\n",
    "    'Банк / Филиал': 'bank'\n",
    "}\n",
    "\n",
    "df = pd.read_excel('./data/prep/bank_gazprombank.xlsx', header=1).rename(new_names, axis=1)\n",
    "df= df[~df[['lat', 'long']].isnull().any(axis=1)].copy()\n",
    "\n",
    "\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 100, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "for name in ['town', 'region', 'lat', 'long', 'region_type', 'town_type', 'loctype', 'atm_type',\n",
    "            'cards', 'access']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "    \n",
    "for name in ['region', 'town', 'region_type', 'town_type', 'loctype', 'atm_type', 'cards', 'access']:\n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in gazprom_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "gazprom_new_features = [PREFIX + '_min_diff']\n",
    "for k in gazprom_diff_k_values:\n",
    "    gazprom_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[gazprom_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Росбанк и партнеры (сайт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = 'partners'\n",
    "logging.info('creating partners features')\n",
    "\n",
    "df = pd.read_csv(\"./data/prep/bank_rosbank.csv\")\n",
    "df = df[~df[['lat', 'long']].isnull().any(axis=1)].copy().reset_index()\n",
    "\n",
    "coords = df[['lat', 'long']].values\n",
    "neigh = NearestNeighbors(metric=distance)\n",
    "neigh.fit(coords)\n",
    "\n",
    "distances, indexes = neigh.kneighbors(data[['lat', 'long']].values, 10, return_distance=True)\n",
    "\n",
    "data[PREFIX + '_dist'] = distances[:, 0]\n",
    "\n",
    "###\n",
    "\n",
    "for name in ['bank', 'region', 'location']:\n",
    "    data[ PREFIX + '_' + name] = df.loc[indexes[:, 0], name].values\n",
    "    \n",
    "    tmp = data.groupby([PREFIX + '_' + name, 'group']).size()\n",
    "    data[PREFIX + '_' + name + '_group_amount'] = \\\n",
    "        data.apply(lambda x: tmp.get((x[PREFIX + '_' + name], x['group']), 0.), axis=1).values\n",
    "        \n",
    "    data[PREFIX + '_' + name + '_amount'] = data[PREFIX + '_' + name].map(data.groupby(PREFIX + '_' + name).size())   \n",
    "    \n",
    "    data[PREFIX + '_' + name + '_rel'] = data[PREFIX + '_' + name + '_group_amount'] / \\\n",
    "            data[PREFIX + '_' + name + '_amount']\n",
    "        \n",
    "res = []\n",
    "for idx, (dists, ids) in enumerate(zip(distances, indexes)):\n",
    "    info = []\n",
    "    diffs = np.array([dists[i + 1] - dists[i] for i in range(len(dists) - 1)])\n",
    "    info.append(diffs[0])\n",
    "    for k in partners_diff_k_values:\n",
    "        info += [diffs[:k].mean(), diffs[:k].std(), diffs[:k].max()]\n",
    "    res.append(info)\n",
    "    \n",
    "partners_new_features = [PREFIX + '_min_diff']\n",
    "for k in partners_diff_k_values:\n",
    "    partners_new_features += [PREFIX + '_dist_' + str(k) + '_' + word for word in ['mean', 'std', 'max']]\n",
    "    \n",
    "data[partners_new_features] = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "group2name = {\n",
    "    496.5: 'Россельхозбанк', 1022.0: 'Ак Барс',\n",
    "    1942.0: 'Альфа-Банк', 3185.5: 'Газпромбанк',\n",
    "    5478.0: 'Уралсиб', 8083.0: 'Росбанк'\n",
    "}\n",
    "\n",
    "atms = pd.read_csv(\"./data/prep/bank_sravni_2.csv\")\n",
    "data['group_bank'] = data['group'].map(group2name)\n",
    "\n",
    "tmp = atms.groupby(['town', 'bank']).size()\n",
    "data['atms_town_group_bank_amount'] = data.apply(lambda x: tmp.get((x['izbir_town'], x['group_bank']), 0.), axis=1)\n",
    "data['izbir_atm_town'] = data['izbir_town'].map(atms.groupby('town').size())\n",
    "data['group_bank_amount'] = data['group_bank'].map(atms.groupby('bank').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features_dict = defaultdict(list)\n",
    "###\n",
    "\n",
    "PREFIX = 'izbir'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'lon', 'voters_in', 'idx']]\n",
    "#features += ['izbir_voters_out']\n",
    "for name in ['type', 'region', 'location_type', 'town', 'address']:\n",
    "    features += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        features += [PREFIX + '_' + name + '_group_' + str(group) + '_amount']    \n",
    "    \n",
    "features_dict[PREFIX] += features\n",
    "\n",
    "### \n",
    "PREFIX = 'city'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'lon', 'population']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'lon', 'population']]\n",
    "\n",
    "for name in ['town', 'region', 'region_type', 'district', 'time']:\n",
    "    features += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "    \n",
    "for name in ['town']:\n",
    "    for group in groups:\n",
    "        features += [PREFIX + '_' + name + '_group_' + str(group) + '_amount']\n",
    "        features_dict[PREFIX] += [PREFIX + '_' + name + '_group_' + str(group) + '_amount']\n",
    "        \n",
    "features += city_diff_features\n",
    "features_dict[PREFIX] += city_diff_features\n",
    "\n",
    "for city in important_coords:\n",
    "    features += ['dist2' + city]\n",
    "    features_dict[PREFIX] += ['dist2' + city]\n",
    "    \n",
    "###\n",
    "for filename in metro_fields:\n",
    "    \n",
    "    features += [filename + '_' + word for word in ['dist', 'lat', 'lon']]\n",
    "    features_dict['metro'] += [filename + '_' + word for word in ['dist', 'lat', 'lon']]\n",
    "    \n",
    "    for name in metro_fields[filename]:\n",
    "        features += [filename + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "        features_dict['metro'] += [filename + '_' + name + word for word in ['_group_amount', '_amount', '_rel']]\n",
    "        \n",
    "    for rad in metro_rad_values:\n",
    "        features += [filename + '_dist_count_' + str(rad)]\n",
    "        features_dict['metro'] += [filename + '_dist_count_' + str(rad)]\n",
    "        \n",
    "    features += [filename + '_' + word for word in metro_new_features]\n",
    "    features_dict['metro'] += [filename + '_' + word for word in metro_new_features]\n",
    "    \n",
    "### initial\n",
    "PREFIX = 'initial'\n",
    "\n",
    "features += ['id', 'loc_null', 'lat', 'long', ]\n",
    "features_dict[PREFIX] += ['id', 'loc_null', 'lat', 'long', ]\n",
    "\n",
    "for name in ['coord']:\n",
    "    features += [PREFIX + '_' + name + word for word in ['_amount', '_group_amount']]#, '_rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_amount', '_group_amount']]\n",
    "    \n",
    "for name in ['coord']:\n",
    "    for group in groups:\n",
    "        features += [PREFIX + '_' + name + '_group_' + str(group) + '_amount']\n",
    "        features_dict[PREFIX] += [PREFIX + '_' + name + '_group_' + str(group) + '_amount']\n",
    "        \n",
    "features += ['group_amount'] # под вопросом. Может быть лик\n",
    "features_dict[PREFIX] += ['group_amount']\n",
    "\n",
    "# rus cities wiki, gks_table\n",
    "features += ['gks_population', 'wiki_town_population', 'wiki_region_population']\n",
    "features_dict[PREFIX] += ['gks_population', 'wiki_town_population', 'wiki_region_population']\n",
    "\n",
    "# fees\n",
    "features += ['fee_min_work2all']\n",
    "features_dict[PREFIX] += ['fee_min_work2all']\n",
    "\n",
    "# atm\n",
    "features += new_atm_features\n",
    "features_dict['atm'] += new_atm_features\n",
    "\n",
    "for k in atm_k_values:\n",
    "    features += ['atm_dist_std_' + str(k)]\n",
    "    features_dict['atm'] += ['atm_dist_std_' + str(k)]\n",
    "    \n",
    "for rad in atm_rad_values:\n",
    "    features += ['atm_dist_count_' + str(rad)]\n",
    "    features_dict['atm'] += ['atm_dist_count_' + str(rad)]\n",
    "    \n",
    "for rad in atm_group_rad_values:\n",
    "    features += [str(group) + str(rad) for group in groups]\n",
    "    features_dict['atm'] += [str(group) + str(rad) for group in groups]\n",
    "\n",
    "# OSM\n",
    "features += osm_features\n",
    "features_dict['osm'] += osm_features\n",
    "\n",
    "# sberbank xls\n",
    "PREFIX = 'sberbank'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['lat', 'long', 'index', 'dist', 'town_amount_outer']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['lat', 'long', 'index', 'dist', 'town_amount_outer']]\n",
    "\n",
    "for name in ['town', 'type', 'region', 'district']:\n",
    "    features += [PREFIX + '_' + name + word for word in ['_amount', '_group_amount', '_rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + word for word in ['_amount', '_group_amount', '_rel']]\n",
    "\n",
    "features += sberbank_new_features\n",
    "features_dict[PREFIX] += sberbank_new_features\n",
    "\n",
    "# rosbank p2p\n",
    "PREFIX = 'rosbank_p2p'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['town', 'region', 'regime']:\n",
    "    features += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "\n",
    "features += rosbank_p2p_new_features\n",
    "features_dict[PREFIX] += rosbank_p2p_new_features\n",
    "\n",
    "# sravni\n",
    "PREFIX = 'sravni'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['bank', 'town', 'service', 'time']:\n",
    "    features += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "\n",
    "features += sravni_new_features\n",
    "features_dict[PREFIX] += sravni_new_features\n",
    "\n",
    "# россельхоз банк\n",
    "PREFIX = 'rshb'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['region', 'access', 'currency', 'shedule']:\n",
    "    features += [PREFIX + '_' + name + '_' + word for word in ['group_amount', 'amount', 'rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + '_' + word for word in ['group_amount', 'amount', 'rel']]\n",
    "\n",
    "features += rshb_new_features\n",
    "features_dict[PREFIX] += rshb_new_features\n",
    "\n",
    "# raiffaizen\n",
    "PREFIX = 'raif'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['time']:\n",
    "    features += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    \n",
    "features += raif_new_features\n",
    "features_dict[PREFIX] += raif_new_features\n",
    "                              \n",
    "# gazprombank\n",
    "PREFIX = 'gazprom'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist', 'lat', 'long']]\n",
    "\n",
    "for name in ['region', 'town', 'region_type', 'town_type', 'loctype', 'atm_type', 'cards', 'access']:\n",
    "    features += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    \n",
    "features += gazprom_new_features\n",
    "features_dict[PREFIX] += gazprom_new_features\n",
    "\n",
    "# partners\n",
    "PREFIX = 'partners'\n",
    "\n",
    "features += [PREFIX + '_' + word for word in ['dist']]\n",
    "features_dict[PREFIX] += [PREFIX + '_' + word for word in ['dist']]\n",
    "\n",
    "for name in ['bank', 'region', 'location']:\n",
    "    features += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "    features_dict[PREFIX] += [PREFIX + '_' + name + '_' + word for word in ['amount', 'group_amount', 'rel']]\n",
    "\n",
    "    \n",
    "features += partners_new_features\n",
    "features_dict[PREFIX] += partners_new_features\n",
    "\n",
    "features += ['atms_town_group_bank_amount', 'izbir_atm_town', 'group_bank_amount']\n",
    "features_dict[PREFIX] += ['atms_town_group_bank_amount', 'izbir_atm_town', 'group_bank_amount']\n",
    "                 \n",
    "#########\n",
    "logging.info('Result: {} features'.format(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HOLDOUT_MODE:\n",
    "\n",
    "    data.to_csv('./data/prep_data_HO.csv', index=False)\n",
    "    np.save('./data/prep_features_HO.npy', features)\n",
    "    np.save('./data/prep_features_dict_HO.npy', features_dict)\n",
    "    \n",
    "else:\n",
    "    data.to_csv('./data/prep_data.csv', index=False)\n",
    "    np.save('./data/prep_features.npy', features)\n",
    "    np.save('./data/prep_features_dict.npy', features_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
