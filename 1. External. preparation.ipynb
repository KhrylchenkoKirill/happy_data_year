{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примечание\n",
    "\n",
    "Исходные трейн и тест лежат в папке ./data под названиями init_train.csv, init_test.csv\n",
    "\n",
    "Абсолютно не гарантируется воспроизводимость внешних данных, поэтому прикладываются исходные данные и обработанные данные в папках ./data/external и ./data/prep соответственно.\n",
    "\n",
    "Также в папке ./data/external лежит файл README, в котором продублирована информация про источники внешних данных без подробностей (некоторые из тех, что лежат там, уже не используются)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание вспомогательных файлов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import re, json, gc, requests, time\n",
    "import urllib.request\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "from bs4 import BeautifulSoup\n",
    "from yandex_geocoder import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Википедия. Список городов России\n",
    "\n",
    "Вручную скопировал по ссылке https://ru.wikipedia.org/wiki/Список_городов_России табличку с городами в файл \"wiki_cities.txt\".\n",
    "\n",
    "Выделяется город, регион, федеральный округ, и население."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/external/wiki_cities.txt')\n",
    "text = f.readlines()\n",
    "\n",
    "def preprocess(text):\n",
    "    splitted = text.lower().split('\\t')\n",
    "    return [el[:-1] for el in splitted[2:-2]] + [int(re.findall('\\d+', splitted[-2])[0])] + \\\n",
    "            [int(re.findall('\\d+', splitted[-1])[0])]\n",
    "\n",
    "df = pd.DataFrame([preprocess(s) for s in text[:-2]], \n",
    "                  columns=['town', 'region', 'federal_district', 'population', 'year'])\n",
    "\n",
    "df.to_csv(\"./data/prep/wiki_cities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метро\n",
    "\n",
    "+ metro_moscow.txt --- скопировано с сайта http://www.lovrikinfo.ru/metrogps.php\n",
    "+ metro_peter.txt --- скопировано с http://quantron-systems.com/ru/article/89\n",
    "+ metro_russia.json --- скачано с https://github.com/hhru/api/blob/master/docs/metro.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Москва\n",
    "\n",
    "f = open('./data/external/metro_moscow.txt')\n",
    "text = f.readlines()\n",
    "df = pd.DataFrame([line.split('\\t') for line in text], columns=['station', 'lat', 'lon'])\n",
    "df[['lon', 'lat']] = df[['lon', 'lat']].astype(float)\n",
    "df.to_csv(\"./data/prep/metro_moscow.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Петербург\n",
    "\n",
    "f = open('./data/external/metro_peter.txt')\n",
    "text = f.readlines()\n",
    "\n",
    "prev_line=''\n",
    "tmp = []\n",
    "data = []\n",
    "flg = 0\n",
    "for line in [line for line in text if line != '\\t\\n']:\n",
    "    if line[:2].isdigit() and flg == 0:\n",
    "        tmp += [prev_line, line]\n",
    "        flg = 1\n",
    "    elif flg == 1:\n",
    "        tmp += [line]\n",
    "        flg = 0\n",
    "        data.append(tmp)\n",
    "        tmp = []\n",
    "    else:\n",
    "        prev_line = line\n",
    "        \n",
    "df = pd.DataFrame(data, columns=['station', 'lat', 'lon'])\n",
    "df[['lon', 'lat']] = df[['lon', 'lat']].astype(float)\n",
    "df['station'] = df['station'].map(lambda x: x[:-1])\n",
    "df.to_csv(\"./data/prep/metro_peter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Россия\n",
    "\n",
    "f = open('./data/external/metro_russia.json')\n",
    "metro_data = json.loads(f.read())\n",
    "\n",
    "station_coords = []\n",
    "for town in metro_data:\n",
    "    for line in town['lines']:\n",
    "        for station in line['stations']:\n",
    "            station_coords.append([town['name'], line['name'], station['name'], station['lat'], station['lng']])\n",
    "            \n",
    "df = pd.DataFrame(station_coords, columns=['town', 'line', 'station', 'lat', 'lon'])\n",
    "df.to_csv(\"./data/prep/metro.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Избирательные участки\n",
    "\n",
    "+ Файл: Russia_merged_uik_data_w_migration.xlsx\n",
    "+ Скачан из: https://drive.google.com/drive/folders/1apRilLMPs02QL9dChWD0h001Yz9IPXLH\n",
    "+ Для удобства переименован в: votes.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb373c321ce42508890cd1ec55e6d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_coords(text):\n",
    "    coord_dict = json.loads(re.sub(\"\\'\", '\\\"', text))\n",
    "    return [coord_dict['lat'], coord_dict['lon']]\n",
    "\n",
    "cols_to_drop = ['uik #', 'addrs', 'koib(1)/keg(2)/none(0)', 'votephone', 'url', 'uikpage', 'phone']\n",
    "votes = pd.read_excel(\"./data/external/votes.xlsx\").drop(cols_to_drop, axis=1)\n",
    "\n",
    "\n",
    "chosen_cols = ['votecoords', 'coords', 'voteaddress', 'address', 'region', 'location_type']\n",
    "chosen_votes = votes.loc[~votes[['votecoords', 'coords', 'voteaddress', 'address']].isnull().any(axis=1), chosen_cols]\n",
    "\n",
    "coords = []\n",
    "for idx, row in tqdm_notebook(chosen_votes.drop_duplicates().iterrows(), leave=False):\n",
    "    for word in ['', 'vote']:\n",
    "        votecoords = parse_coords(row[word + 'coords'])\n",
    "        coords.append([row[word + 'address']] + votecoords + [word, row['region'], row['location_type']])\n",
    "        \n",
    "votes_info = pd.DataFrame(coords, columns=['address', 'lat', 'lon', 'type', 'region', 'location_type'])\n",
    "votes_info.drop(votes_info.index[votes_info['lon'] == ''], inplace=True)\n",
    "votes_info.reset_index(drop=True, inplace=True)\n",
    "\n",
    "for ctype in ['lon', 'lat']:\n",
    "    votes_info[ctype] = votes_info[ctype].map(lambda x: re.sub(' ', '', x))\n",
    "    \n",
    "votes_info[['lon', 'lat']] = votes_info[['lon', 'lat']].astype(float)\n",
    "\n",
    "votes_info['voters_in'] = votes_info['address'].map(votes.groupby('voteaddress')['voters_in'].sum())\n",
    "votes_info['voters_out'] = votes_info['address'].map(votes.groupby('voteaddress')['voters_out'].sum())\n",
    "\n",
    "\n",
    "patterns = ['город ([^,]+)', 'г\\. ([^,]+)', 'г\\.([^,]+)', 'село ([^,]+)', 'поселок ([^,]+)',\n",
    "           'п\\. ([^,]+)', 'п\\.([^,]+)', 'пос\\.([^,]+)', 'с\\. ([^,]+)', 'с\\.([^,]+)',\n",
    "            'посёлок ([^,]+)', 'поселение ([^,]+)', 'деревня ([^,]+)', 'дер\\. ([^,]+)',\n",
    "            'д\\. ([^,]+)', 'аул ([^,]+)', 'город-курорт ([^,]+)', '(северодвинск)', \n",
    "            ', ([^,]+) городское поселение', ', ([^,]+) сельское поселение', 'дер\\.([^,]+)',\n",
    "            'гор\\.([^,]+)', 'городской округ ([^,]+)', ', ([^,]+) городской округ',\n",
    "            'пгт ([^,]+)', 'пгт\\. ([^,]+)','д\\.([^,]+)',\n",
    "            'закрытое административно-территориальное образование ([^,]+)',\n",
    "            'городское поселения ([^,]+)',\n",
    "            'станица ([^,]+)', 'хутор ([^,]+)', \n",
    "            'аал ([^,]+)',\n",
    "            'сумон ([^,]+)'\n",
    "           ]\n",
    "\n",
    "pattern = ''\n",
    "for p in patterns:\n",
    "    pattern +=p + '|'\n",
    "pattern = pattern[:-1]\n",
    "\n",
    "re_pattern = re.compile(pattern)\n",
    "\n",
    "def get_town(text):\n",
    "    found = re.findall(re_pattern, text)\n",
    "    if len(found) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        found = found[0]\n",
    "    for record in found:\n",
    "        if record != '':\n",
    "            return record\n",
    "    return np.nan\n",
    "\n",
    "def clean_town(text):\n",
    "    if 'город ' in text:\n",
    "        return re.findall('город ([^\"]+)', text)[0]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def get_idx(x):\n",
    "    found = re.findall('^(\\d+),', x)\n",
    "    if len(found) > 0:\n",
    "        return int(found[0])\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "votes_info.drop_duplicates(['lat', 'lon'], inplace=True)\n",
    "votes_info['town'] = votes_info['address'].map(lambda x: get_town(x.lower()))\n",
    "votes_info.dropna(inplace=True)\n",
    "votes_info['town'] = votes_info['town'].map(clean_town)\n",
    "votes_info['idx'] = votes_info['address'].map(get_idx)\n",
    "votes_info.reset_index(drop=True, inplace=True)\n",
    "\n",
    "votes_info.to_csv(\"./data/prep/votes.csv\", index=False)\n",
    "\n",
    "del votes\n",
    "del votes_info\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Население регионов\n",
    "\n",
    "Файл Tabl-01-18.xls из архива за 2018 год по ссылке http://www.gks.ru/wps/wcm/connect/rosstat_main/rosstat/ru/statistics/publications/catalog/afc8ea004d56a39ab251f2bafc3a6fce.\n",
    "\n",
    "Переименован в population_gks.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop2izbir = {\n",
    "    'г. Москва': 'город Москва',\n",
    "    'г.Санкт-Петербург ': 'город Санкт-Петербург',\n",
    "    'Республика Татарстан': 'Республика Татарстан (Татарстан)',\n",
    "    'Ямало-Ненецкий авт. округ': 'Ямало-Ненецкий автономный округ',\n",
    "    'Республика Адыгея': 'Республика Адыгея (Адыгея)',\n",
    "    'Архангельская область без Ненецкого авт. округа': 'Архангельская область',\n",
    "    'Чувашская Республика': 'Чувашская Республика - Чувашия',\n",
    "    'Тюменская область включая авт. округа  ': 'Тюменская область',\n",
    "    'Республика Северная Осетия-Алания':  'Республика Северная Осетия - Алания',\n",
    "    'Ханты-Мансийский авт. округ': 'Ханты-Мансийский автономный округ - Югра', \n",
    "    'Республика Марий Эл ': 'Республика Марий Эл'\n",
    "}\n",
    "\n",
    "\n",
    "col_names = ['region', 'population', 'city_population', 'country_population', \n",
    "             'population17', 'city_population17', 'country_population17']\n",
    "df = pd.read_excel('./data/external/population_gks.xls', header=5).reset_index()\n",
    "df.columns = col_names\n",
    "df['region'] = df['region'].apply(lambda x: pop2izbir[x] if x in pop2izbir else x)\n",
    "\n",
    "df.to_csv(\"./data/prep/population_gks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные по городам России\n",
    "#### Anton Zhiyanov (nalgeon)'s github\n",
    "\n",
    "Файл cities.csv --- скачан по ссылке https://gist.github.com/nalgeon/5307af065ff0e3bc97927c832fabe26b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/external/cities.csv\")\\\n",
    "       .rename({'Регион': 'region', 'Город': 'town', 'Население': 'population'}, axis=1)\n",
    "\n",
    "df.to_csv(\"./data/prep/cities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Плотность населения\n",
    "\n",
    "Файл statdata_population.txt --- скопировано с http://www.statdata.ru/nasel_regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('./data/external/population_statdata.txt')\\\n",
    "       .rename({'Субъект России': 'region'}, axis=1).replace(',', '.')\n",
    "    \n",
    "names = ['Плотн.насел., чел/км²', 'Население', 'Площадь,км²']\n",
    "new_names = ['density', 'populus', 'area']\n",
    "\n",
    "df[names[0]] = df[names[0]].apply(lambda x: re.sub(',', '.', x)).astype(float)\n",
    "df[names[1]] = df[names[1]].apply(lambda x: ''.join(x.split())).astype(int)\n",
    "df[names[2]] = df[names[2]].apply(lambda x: ''.join(x.split())).astype(int)\n",
    "df.columns = ['idx', 'region'] + new_names + ['FO']\n",
    "\n",
    "df.to_csv(\"./data/prep/population_statdata.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прожиточный минимум\n",
    "Документ скачан с http://www.gks.ru/free_doc/new_site/population/urov/vpm/proj-min.html.\n",
    "\n",
    "Переименован в fee_min.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/external/fee_min.txt')\n",
    "text = f.readlines()\n",
    "\n",
    "df = pd.DataFrame([text[6 * i : 6 * (i + 1)] for i in range(int(len(text) / 6.))], \n",
    "                  columns=['region', 'period', 'fee_all', 'fee_work', 'fee_pension', 'fee_child'])\n",
    "\n",
    "df['region'] = df['region'].apply(lambda x: x[:-1])\n",
    "df['region'] = df['region'].apply(lambda x: pop2izbir[x] if x in pop2izbir else x)\n",
    "df[['fee_all', 'fee_work', 'fee_pension', 'fee_child']] = df[['fee_all', 'fee_work', 'fee_pension', 'fee_child']]\\\n",
    "                .astype(int)\n",
    "    \n",
    "df.to_csv(\"./data/prep/fee_min.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Средняя зарплата по регионам\n",
    "\n",
    "fee_avg.txt --- скопировано с https://visasam.ru/russia/rabotavrf/zarplaty-v-rossii.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/external/fee_avg.txt')\n",
    "\n",
    "text = f.readlines()[0]\n",
    "text = re.findall('(\\w+ \\d+ \\d+)', text)\n",
    "text = [re.sub('(\\d+) (\\d+)', r'\\1.\\2', line).split() for line in text]\n",
    "\n",
    "stats = pd.DataFrame(text, columns=['town', 'fee'])\n",
    "stats['town'] = stats['town'].map(lambda x: x.lower())\n",
    "stats['fee'] = stats['fee'].astype(float)\n",
    "\n",
    "stats.to_csv(\"./data/prep/fee_avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заработные платы в социальной и научной сферах\n",
    "Скачано с http://www.gks.ru/free_doc/new_site/population/trud/itog_monitor/itog-monitor05-18.html.\n",
    "\n",
    "Переименован в fee_work.xlsx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fees = pd.read_excel('./data/external/fee_work.xlsx', header=2, nrows=99)\n",
    "fees = fees.replace('…1)', np.nan).reset_index().rename({'index': 'region'}, axis=1)\n",
    "fees = fees.replace('-', np.nan)\n",
    "fees.drop(fees.index[fees['region'].isin({'А', 'в том числе:'})], axis=0, inplace=True)\n",
    "fees['region'] = fees['region'].apply(lambda x: pop2izbir[x] if x in pop2izbir else x)\n",
    "\n",
    "fees.to_csv(\"./data/prep/fee_work.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Банкоматы росбанка, p2p.\n",
    "\n",
    "Файл bank_rosbank_p2p.xls: скачан по ссылке https://www.rosbank.ru/files/p2p/P2Pb.xls.\n",
    "\n",
    "Нахождение координат по адресам с помощью яндекс геокодера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1db56661ae4c6c84dcc24d184ac8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1808), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./data/external/bank_rosbank_p2p.xls').rename({'Адрес': 'address'}, axis=1)\n",
    "\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for address in tqdm_notebook(df['address'].values, leave=False):\n",
    "    try:\n",
    "        long, lat = Client.coordinates(address)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(long)\n",
    "    except Exception as e:\n",
    "        longitudes.append(np.nan)\n",
    "        latitudes.append(np.nan)\n",
    "        \n",
    "df['lat'] = latitudes\n",
    "df['lat'] = df['lat'].astype(float)\n",
    "\n",
    "df['long'] = longitudes\n",
    "df['long'] = df['long'].astype(float)\n",
    "\n",
    "df.to_csv(\"./data/prep/bank_rosbank_p2p.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Банкоматы Сбербанка\n",
    "\n",
    "bank_sberbank.xlsx - файл скинули в ODS канале контеста, также можно найти на официальном сайте сбербанка.\n",
    "\n",
    "Долго работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sber = pd.read_excel('./data/external/bank_sberbank.xlsx', encoding='cp1251')\\\n",
    "         .rename({'Название населенного пункта': 'town'}, axis=1)\n",
    "    \n",
    "addr = []\n",
    "for row in sber.values:\n",
    "    addr.append(\" \".join([str(el) for el in row[1:].tolist() if el == el and el != 'Банкомат']))\n",
    "    \n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for address in tqdm_notebook(addr):\n",
    "    try:\n",
    "        long, lat = Client.coordinates(address)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(long)\n",
    "    except Exception as e:\n",
    "        longitudes.append(np.nan)\n",
    "        latitudes.append(np.nan)\n",
    "        \n",
    "sber['lat'] = latitudes\n",
    "sber['lat'] = sber['lat'].astype(float)\n",
    "\n",
    "sber['long'] = longitudes\n",
    "sber['long'] = sber['long'].astype(float)\n",
    "\n",
    "sber.to_csv('./data/prep/bank_sberbank.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Газпромбанк\n",
    "\n",
    "Скачивание файла gazprombank.xlsx с сайта https://www.gazprombank.ru/ajax/ru/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/prep/bank_gazprombank.xlsx',\n",
       " <http.client.HTTPMessage at 0x7fb6ed7ec6a0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.gazprombank.ru/ajax/ru/atms_to_xlsx.php'  \n",
    "urllib.request.urlretrieve(url, './data/prep/bank_gazprombank.xlsx')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Россельхозбанк\n",
    "\n",
    "Парсинг сайта https://www.rshb.ru/atms/moscow на предмет банкоматов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296702973e504ef6b004597a12ccad24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=132), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "page = requests.get('https://www.rshb.ru/atms/moscow')\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "regions = [(line['data-branch-code'], line.contents[0][14:-8]) \n",
    "           for line in soup.find('body').find_all('span') if 'data-region-id' in line.attrs]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for region_codename, region_name in tqdm_notebook(regions, leave=False):\n",
    "    params = { 'branchCode': region_codename,  'locality': 'Все',  'type': 'atms.list'}\n",
    "    f = requests.post('https://www.rshb.ru/ajax/get-data.php', data=params) \n",
    "    raw_json = f.json()['atmItems']\n",
    "    tmp_df = pd.DataFrame.from_dict(raw_json, orient='index')\n",
    "    tmp_df['region'] = region_name\n",
    "    \n",
    "    df = df.append(tmp_df, sort=False)\n",
    "    \n",
    "df.to_csv(\"./data/prep/bank_rshb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Райффайзенбанк\n",
    "\n",
    "Парсинг сайта https://www.raiffeisen.ru/common/branch_atm/ на предмет банкоматов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\r"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'gz':1,\n",
    "    'filter': 'rub1',\n",
    "    'act': 'listAtmP',\n",
    "    'ready': 0\n",
    "}\n",
    "\n",
    "link = 'https://www.raiffeisen.ru/common/branch_atm/new_ajax.php'\n",
    "\n",
    "atms = []\n",
    "soup_len = 1\n",
    "while soup_len != 0:\n",
    "    f = requests.get(link, params=params)\n",
    "    soup = BeautifulSoup(f.content, 'html.parser')\n",
    "    soup_len = len(soup)\n",
    "    \n",
    "    for atm in soup.find_all(name='div', attrs={'class': 'e-office-item'}):\n",
    "        coords = atm.contents[3].contents[1].attrs['data-coords']\n",
    "        address = atm.contents[3].contents[1].contents[0]\n",
    "        time = atm.contents[3].contents[3].contents[0]\n",
    "        atms.append([address, coords, time])\n",
    "        \n",
    "    params['ready'] += 6\n",
    "    \n",
    "    print(params['ready'], end='\\r')\n",
    "    \n",
    "pd.DataFrame(atms, columns=['address', 'coords', 'time']).to_csv(\"./data/prep/bank_raif.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Росбанк\n",
    "\n",
    "Парсинг сайта https://www.rosbank.ru/ru/atms/ на предмет банкоматов.\n",
    "\n",
    "rosbank_regions.txt создан копированием исходного кода страницы, вылезающей при выборе региона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm_notebook\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "file = open('./data/external/rosbank_regions.txt')\n",
    "regions_txt = file.readlines()\n",
    "\n",
    "regions = []\n",
    "ids = []\n",
    "for line in regions_txt:\n",
    "    if 'city__body_list' in line:\n",
    "        regions += [re.findall('title=\"(.+)\">', s)[0] for s in line.split('/li')[:-1]]\n",
    "        ids += [int(el) for el in re.findall('\\?region=(\\d+)\" title', line)]\n",
    "        \n",
    "region2idx = dict(zip(regions, ids))\n",
    "\n",
    "def get_text(region_id, pagenumber):\n",
    "    link = \"https://www.rosbank.ru/ru/atms/list.php?page_25=\" + str(pagenumber)\n",
    "    f = requests.get(link, cookies={'regionrb': str(region_id)})\n",
    "    return f\n",
    "\n",
    "def parse(page):\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    banks = [el.text for el in soup.find_all('div', class_='address-logo')]\n",
    "    addresses = [el.text for el in soup.find_all('div', class_=\"address-title\")]\n",
    "    locations = [el.text for el in soup.find_all('div', class_=\"address-type\")]\n",
    "    time = [el.text for el in soup.find_all('div', class_=\"page-atm__table_col page-atm__table_col--time\")]\n",
    "    cash = [el.text for el in soup.find_all('div', class_=\"page-atm__table_col page-atm__table_col--currency\")]\n",
    "    metros = [[el.text for el in metros.find_all('div')] for metros in soup.find_all('ul', class_=\"address-metro\")] \n",
    "    ids = [re.findall('\\d+', el.find('a').attrs['href'])[0] for el in soup.find_all('div', class_=\"address-map\")]\n",
    "\n",
    "    return [list(el) for el in list(zip(banks, ids, addresses, locations, time, metros, cash))]\n",
    "\n",
    "\n",
    "res = []\n",
    "for region in tqdm_notebook(region2idx):\n",
    "    print(region + '...')\n",
    "    region_id = region2idx[region]\n",
    "    \n",
    "    pagenumber = 1\n",
    "    page = get_text(region_id, pagenumber)\n",
    "    tmp = [re.findall('page active\">(\\d+)</a></li>', line) \n",
    "                       for line in page.text.splitlines() if 'pagination-page active' in line]\n",
    "    if len(tmp) > 0:\n",
    "        real_pagenumber = tmp[0][0]\n",
    "        print(real_pagenumber, end='\\r')\n",
    "    else:\n",
    "        print(1, end='\\r')\n",
    "    res += [[region] + el for el in parse(page)]\n",
    "    \n",
    "    \n",
    "    if len(tmp) > 0:\n",
    "        pagenumber += 1\n",
    "        page = get_text(region_id, pagenumber)\n",
    "        tmp = [re.findall('page active\">(\\d+)</a></li>', line) \n",
    "                       for line in page.text.splitlines() if 'pagination-page active' in line]\n",
    "        if len(tmp) > 0:\n",
    "            real_pagenumber = tmp[0][0]\n",
    "            print(real_pagenumber, end='\\r')\n",
    "        else:\n",
    "            print(1, end='\\r')\n",
    "\n",
    "    while real_pagenumber != '1' and len(tmp) > 0:\n",
    "        res += [[region] + el for el in parse(page)]\n",
    "        pagenumber += 1\n",
    "        page = get_text(region_id, pagenumber)\n",
    "        tmp = [re.findall('page active\">(\\d+)</a></li>', line) \n",
    "                       for line in page.text.splitlines() if 'pagination-page active' in line]\n",
    "        if len(tmp) > 0:\n",
    "            real_pagenumber = tmp[0][0]\n",
    "            print(real_pagenumber, end='\\r')\n",
    "        else:\n",
    "            print(1, end='\\r')\n",
    "            \n",
    "df = pd.DataFrame(res, columns=['region', 'bank', 'id', 'address', 'location', 'time', 'metro', 'cash'])\n",
    "\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "addr = df['address'].values\n",
    "for address in tqdm_notebook(addr):\n",
    "    try:\n",
    "        long, lat = Client.coordinates(address)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(long)\n",
    "    except Exception as e:\n",
    "        longitudes.append(np.nan)\n",
    "        latitudes.append(np.nan)\n",
    "        \n",
    "df['lat'] = latitudes\n",
    "df['lat'] = df['lat'].astype(float)\n",
    "\n",
    "df['long'] = longitudes\n",
    "df['long'] = df['long'].astype(float)\n",
    "\n",
    "df['bank'] = df['bank'].apply(lambda x: \" \".join(x.split()))\n",
    "\n",
    "df.to_csv(\"./data/prep/bank_rosbank.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сайт sravni.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_addr(text):\n",
    "    parts = text.split(',')\n",
    "    return [parts[0], parts[1][1:], parts[2][1:]]\n",
    "\n",
    "link = 'https://www.sravni.ru/banki/spisok-bankomatov/'\n",
    "f = requests.get(link)\n",
    "banks = [(re.findall('>(.+)</a>', line)[0], re.findall('spisok-bankomatov-(.+)/\">', line)[0]) \n",
    "     for line in f.text.splitlines() if '<a href=\"/banki/spisok-bankomatov' in line and \n",
    "         all([word not in line for word in {'Список банкоматов', 'Сбербанк России страница'}])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(bank_url, atm_id):\n",
    "\n",
    "    link = \"https://www.sravni.ru/bank/\" + bank_url + \"/bankomat/\" + atm_id + '/'\n",
    "    f = requests.get(link)\n",
    "    text = f.text.splitlines()\n",
    "    \n",
    "    tmp = []\n",
    "    time = []\n",
    "    services = []\n",
    "\n",
    "    flag = 0 \n",
    "    for idx, line in enumerate(text):\n",
    "\n",
    "        if flag == 0 and 'hoursAvailable' in line:\n",
    "            flag = 1\n",
    "        elif flag == 1:\n",
    "            if line == '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>':\n",
    "                tmp.append(time)\n",
    "                flag = 2\n",
    "            else:\n",
    "                time.append(re.sub('\\t|<div>|</div>', '', line))\n",
    "        elif flag == 2 and 'productSupported' in line:\n",
    "            flag = 3\n",
    "        elif flag == 3:\n",
    "            if line == '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t</div>':\n",
    "                flag = 4\n",
    "                tmp.append(services)\n",
    "                break\n",
    "            elif line != '\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t<div class=\"text\">':\n",
    "                services.append(re.sub('\\t|<span>|</span>', '', line))\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atms = []\n",
    "for bank_name, bank_url in tqdm_notebook(banks[266:], leave=False):\n",
    "    print(bank_name + '...')\n",
    "    link = \"https://www.sravni.ru/banki/spisok-bankomatov-\" + bank_url + \"/\"\n",
    "    f = requests.get(link)\n",
    "    counter = 0\n",
    "    print(counter, end='\\r')\n",
    "    for line in f.text.splitlines():\n",
    "        if 'href=\"/bank/' + bank_url + '/bankomat/' in line:\n",
    "            counter += 1\n",
    "            print(counter, end='\\r')\n",
    "            atm_id = re.findall('/bankomat/(\\d+)/\">', line)[0]\n",
    "            atm_address = re.sub('\\t.+\">|</a>', '', line) \n",
    "            try:\n",
    "                atm_features = get_features(bank_url, atm_id)\n",
    "            except Exception as e:\n",
    "                time.sleep(0.5)\n",
    "                atm_features = get_features(bank_url, atm_id)\n",
    "            atms.append([atm_id, bank_name, atm_address] + atm_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(atms, columns=['id', 'bank', 'address', 'time', 'service'])\n",
    "df['town'] = df['address'].apply(lambda x: x.lower().split(',')[0])\n",
    "df['town'] = df['address'].apply(lambda x: re.findall('\\w+', x.lower())[0])\n",
    "df['town'] = df['address'].apply(lambda x: x.lower().split(',')[0].split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yandex_geocoder import Client\n",
    "\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for address in tqdm_notebook(df['address'].values):\n",
    "    try:\n",
    "        long, lat = Client.coordinates(address)\n",
    "        latitudes.append(lat)\n",
    "        longitudes.append(long)\n",
    "    except Exception as e:\n",
    "        longitudes.append(np.nan)\n",
    "        latitudes.append(np.nan)\n",
    "        \n",
    "df['lat'] = latitudes\n",
    "df['lat'] = df['lat'].astype(float)\n",
    "\n",
    "df['long'] = longitudes\n",
    "df['long'] = df['long'].astype(float)\n",
    "\n",
    "#df.to_csv(\"./data/prep/bank_sravni_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atms = atms[~atms[['lat', 'long']].isnull().any(axis=1)].copy()  # оставим только банкоматы с координатами\n",
    "atms.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('час\\.', '', text)\n",
    "    text = re.sub('(\\d\\d)\\.(\\d\\d)\\.', r'\\1:\\2', text)\n",
    "    text = re.sub('00(\\d)', r'0\\1', text)\n",
    "    text = re.sub('( \\d+.\\d+):', r'\\1-', text)\n",
    "    text = re.sub('ежедневно, ', 'ежедневно: ', text)\n",
    "    text = re.sub('кр([^у])', r'\\1', text)\n",
    "    text = re.sub('вск', 'вс', text)\n",
    "    text = re.sub(' -- |–| - ', '-', text)\n",
    "    text = re.sub(' -- |–| - ', '-', text)\n",
    "    text = re.sub(\"(пн-пт) \", r'\\1: ', text)\n",
    "    text = re.sub(\"(сб-вс) \", r'\\1: ', text)\n",
    "    text = re.sub(\" (сб) \", r' \\1:', text)\n",
    "    text = re.sub(\" (вс)\", r' \\1:', text)\n",
    "    text = re.sub('вс\\.- ', 'вс: ', text)\n",
    "    text = re.sub('сб – |сб - |сб ', 'сб: ', text)\n",
    "    text = re.sub('\\.', ':', text)\n",
    "    text = re.sub(\":0'\", \":00'\", text)\n",
    "    text = re.sub('с ([\\d+|:]+) до ([\\d+|:]+)', r'\\1-\\2', text)\n",
    "    text = re.sub(' (\\d\\d)-', r' \\1:00-', text)\n",
    "    text = re.sub(' (\\d)-', r' 0\\1:00-', text)\n",
    "    text = re.sub(' (\\d:)', r' 0\\1', text)\n",
    "    text = re.sub('-(\\d\\d) ', r'-\\1:00 ', text)\n",
    "    text = re.sub('-(\\d\\d),', r'-\\1:00,', text)\n",
    "    text = re.sub(\"-(\\d\\d)'\", r\"-\\1:00'\", text)\n",
    "    text = re.sub('24:00', '00:00', text)\n",
    "    return text\n",
    "\n",
    "workdays = ['пн', 'вт', 'ср', 'чт', 'пт']\n",
    "weekends = ['сб', 'вс']\n",
    "weekdays = workdays + weekends\n",
    "\n",
    "def get_time(text, name):\n",
    "    tmp = re.findall(name + \": ([\\d+|:|\\-|\\.]+)|\" + name + \": ([а-я]+)\" , text)\n",
    "    if len(tmp) == 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        tmp = tmp[0]\n",
    "    for val in list(tmp):\n",
    "            if val != '':\n",
    "                if val == 'круглосуточно':\n",
    "                    return 24.\n",
    "                elif val == 'выходной':\n",
    "                    return 0.\n",
    "                else:\n",
    "                    val1, val2 = val.split('-')[:2]\n",
    "                    return (pd.to_datetime(val2) - pd.to_datetime(val1)).components.hours\n",
    "    \n",
    "def f(text):\n",
    "    text = clean(text)\n",
    "    tmp = dict()\n",
    "    if 'пн-вс' in text:\n",
    "        t = get_time(text, 'пн-вс')\n",
    "        for day in weekdays:\n",
    "            tmp[day] = t\n",
    "    elif 'ежедневно' in text:\n",
    "        t = get_time(text, 'ежедневно')\n",
    "        for day in workdays:\n",
    "            tmp[day] = t\n",
    "    else:\n",
    "        if 'пн-пт' in text:\n",
    "            t = get_time(text, 'пн-пт')\n",
    "            for day in workdays:\n",
    "                tmp[day] = t\n",
    "        if 'сб-вс' in text:\n",
    "            t = get_time(text, 'сб-вс')\n",
    "            for day in weekends:\n",
    "                tmp[day] = t\n",
    "        if 'ср-вс' in text:\n",
    "            t = get_time(text, 'сб-вс')\n",
    "            for day in ['ср', 'чт', 'пт'] + weekends:\n",
    "                tmp[day] = t\n",
    "        if 'пн-вт' in text:\n",
    "            t = get_time(text, 'пн-вт')\n",
    "            for day in ['пн', 'вт']:\n",
    "                tmp[day] = t\n",
    "        if 'пн-чт' in text:\n",
    "            t = get_time(text, 'пн-чт')\n",
    "            for day in ['пн', 'вт', 'ср', 'чт']:\n",
    "                tmp[day] = t\n",
    "        if 'пт-вс' in text:\n",
    "            t = get_time(text, 'пт-вс')\n",
    "            for day in ['пт', 'сб', 'вс']:\n",
    "                tmp[day] = t\n",
    "        if 'пн-сб' in text:\n",
    "            t = get_time(text, 'пн-чт')\n",
    "            for day in workdays + ['сб']:\n",
    "                tmp[day] = t\n",
    "        \n",
    "        for day in workdays + weekends:\n",
    "            if \"'\" + day + \":\" in text:\n",
    "                tmp[day] = get_time(text, day)\n",
    "    if len(tmp) > 0:\n",
    "        return tmp\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "def analyze(x):\n",
    "    if x == x:\n",
    "        work = [x.get(el, 0.) for el in workdays]\n",
    "        end = [x.get(el, 0.) for el in weekends]\n",
    "        \n",
    "        return [np.sum(work), np.mean(work), np.max(work), np.min(work)] \\\n",
    "                + [np.sum(end), np.mean(end), np.max(end), np.min(end)]\n",
    "    else:\n",
    "        return [0] * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = atms['time'].apply(lambda x: analyze(f(x)) if x == x else [0] * 8)\n",
    "\n",
    "atm_words = []\n",
    "for prefix in ['work', 'end']:\n",
    "    atm_words += [prefix + '_time_' + word for word in ['sum', 'mean', 'max', 'min']]\n",
    "    \n",
    "atms[atm_words] = pd.DataFrame(tmp.tolist())\n",
    "\n",
    "atms.to_csv(\"./data/prep/bank_sravni_2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
